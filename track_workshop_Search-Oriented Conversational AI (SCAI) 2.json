[{"content":{"abstract":"The challenges of building knowledge-grounded retrieval-based chatbots lie in how to ground a conversation on its background knowledge and how to match response candidates with both context and knowledge simultaneously. This paper proposes a method named Filtering before Iteratively REferring (FIRE) for this task. In this method, a context filter and a knowledge filter are first built, which derive knowledge-aware context representations and context-aware knowledge representations respectively by global and bidirectional attention. Besides, the entries irrelevant to the conversation are discarded by the knowledge filter. After that, iteratively referring is performed between context and response representations as well as between knowledge and response representations, in order to collect deep matching features for scoring response candidates. Experimental results show that FIRE outperforms previous methods by margins larger than 2.8% and 4.1% on the PERSONA-CHAT dataset with original and revised personas respectively, and margins larger than 3.1% on the CMU_DoG dataset in terms of top-1 accuracy. We also show that FIRE is more interpretable by visualizing the knowledge grounding process.","authors":["Jia-Chen Gu","Zhenhua Ling","Quan Liu","Zhigang Chen","Xiaodan Zhu"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.127","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Filtering before Iteratively Referring for Knowledge-Grounded Response Selection in Retrieval-Based Chatbots","tldr":"The challenges of building knowledge-grounded retrieval-based chatbots lie in how to ground a conversation on its background knowledge and how to match response candidates with both context and knowledge simultaneously. This paper proposes a method n...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.1175","presentation_id":"38940705","rocketchat_channel":"paper-scai-1175","speakers":"Jia-Chen Gu|Zhenhua Ling|Quan Liu|Zhigang Chen|Xiaodan Zhu","title":"Filtering before Iteratively Referring for Knowledge-Grounded Response Selection in Retrieval-Based Chatbots"},{"content":{"abstract":"Neural response generative models have achieved remarkable progress in recent years but tend to yield irrelevant and uninformative responses. One of the reasons is that encoder-decoder based models always use a single decoder to generate a complete response at a stroke. This tends to generate high-frequency function words with less semantic information rather than low-frequency content words with more semantic information. To address this issue, we propose a content-aware model with two-stage decoding process named Two-stage Dialogue Generation (TSDG). We separate the decoding process of content words and function words so that content words can be generated independently without the interference of function words. Experimental results on two datasets indicate that our model significantly outperforms several competitive generative models in terms of automatic and human evaluation.","authors":["Junsheng Kong","Zhicheng Zhong","Yi Cai","Xin Wu","Da Ren"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.192","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"TSDG: Content-aware Neural Response Generation with Two-stage Decoding Process","tldr":"Neural response generative models have achieved remarkable progress in recent years but tend to yield irrelevant and uninformative responses. One of the reasons is that encoder-decoder based models always use a single decoder to generate a complete r...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.1735","presentation_id":"38940706","rocketchat_channel":"paper-scai-1735","speakers":"Junsheng Kong|Zhicheng Zhong|Yi Cai|Xin Wu|Da Ren","title":"TSDG: Content-aware Neural Response Generation with Two-stage Decoding Process"},{"content":{"abstract":"General-purpose pretrained sentence encoders such as BERT are not ideal for real-world conversational AI applications; they are computationally heavy, slow, and expensive to train. We propose ConveRT (Conversational Representations from Transformers), a pretraining framework for conversational tasks satisfying all the following requirements: it is effective, affordable, and quick to train. We pretrain using a retrieval-based response selection task, effectively leveraging quantization and subword-level parameterization in the dual encoder to build a lightweight memory- and energy-efficient model. We show that ConveRT achieves state-of-the-art performance across widely established response selection tasks. We also demonstrate that the use of extended dialog history as context yields further performance gains. Finally, we show that pretrained representations from the proposed encoder can be transferred to the intent classification task, yielding strong results across three diverse data sets. ConveRT trains substantially faster than standard sentence encoders or previous state-of-the-art dual encoders. With its reduced size and superior performance, we believe this model promises wider portability and scalability for Conversational AI applications.","authors":["Matthew Henderson","I\u00f1igo Casanueva","Nikola Mrk\u0161i\u0107","Pei-Hao Su","Tsung-Hsien Wen","Ivan Vuli\u0107"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.196","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"ConveRT: Efficient and Accurate Conversational Representations from Transformers","tldr":"General-purpose pretrained sentence encoders such as BERT are not ideal for real-world conversational AI applications; they are computationally heavy, slow, and expensive to train. We propose ConveRT (Conversational Representations from Transformers)...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.1761-ws4","presentation_id":"38940707","rocketchat_channel":"paper-scai-1761-ws4","speakers":"Matthew Henderson|I\u00f1igo Casanueva|Nikola Mrk\u0161i\u0107|Pei-Hao Su|Tsung-Hsien Wen|Ivan Vuli\u0107","title":"ConveRT: Efficient and Accurate Conversational Representations from Transformers"},{"content":{"abstract":"The ubiquitous nature of dialogue systems and their interaction with users generate an enormous amount of data. Can we improve chatbots using this data? A self-feeding chatbot improves itself by asking natural language feedback when a user is dissatisfied with its response and uses this feedback as an additional training sample. However, user feedback in most cases contains extraneous sequences hindering their usefulness as a training sample. In this work, we propose a generative adversarial model that converts noisy feedback into a plausible natural response in a conversation. The generator\u2019s goal is to convert the feedback into a response that answers the user\u2019s previous utterance and to fool the discriminator which distinguishes feedback from natural responses. We show that augmenting original training data with these modified feedback responses improves the original chatbot performance from 69.94%to 75.96% in ranking correct responses on the PERSONACHATdataset, a large improvement given that the original model is already trained on 131k samples.","authors":["Makesh Narsimhan Sreedhar","Kun Ni","Siva Reddy"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.221","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Learning Improvised Chatbots from Adversarial Modifications of Natural Language Feedback","tldr":"The ubiquitous nature of dialogue systems and their interaction with users generate an enormous amount of data. Can we improve chatbots using this data? A self-feeding chatbot improves itself by asking natural language feedback when a user is dissati...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.1947","presentation_id":"38940708","rocketchat_channel":"paper-scai-1947","speakers":"Makesh Narsimhan Sreedhar|Kun Ni|Siva Reddy","title":"Learning Improvised Chatbots from Adversarial Modifications of Natural Language Feedback"},{"content":{"abstract":"In the context of chit-chat dialogues it has been shown that endowing systems with a persona profile is important to produce more coherent and meaningful conversations. Still, the representation of such personas has thus far been limited to a fact-based representation (e.g. \u201cI have two cats.\u201d). We argue that these representations remain superficial w.r.t. the complexity of human personality. In this work, we propose to make a step forward and investigate stance-based persona, trying to grasp more profound characteristics, such as opinions, values, and beliefs to drive language generation. To this end, we introduce a novel dataset allowing to explore different stance-based persona representations and their impact on claim generation, showing that they are able to grasp abstract and profound aspects of the author persona.","authors":["Thomas Scialom","Serra Sinem Tekiro\u011flu","Jacopo Staiano","Marco Guerini"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.238","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Toward Stance-based Personas for Opinionated Dialogues","tldr":"In the context of chit-chat dialogues it has been shown that endowing systems with a persona profile is important to produce more coherent and meaningful conversations. Still, the representation of such personas has thus far been limited to a fact-ba...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.2041","presentation_id":"38940704","rocketchat_channel":"paper-scai-2041","speakers":"Thomas Scialom|Serra Sinem Tekiro\u011flu|Jacopo Staiano|Marco Guerini","title":"Toward Stance-based Personas for Opinionated Dialogues"},{"content":{"abstract":"Dialogue level quality estimation is vital for optimizing data driven dialogue management. Current automated methods to estimate turn and dialogue level user satisfaction employ hand-crafted features and rely on complex annotation schemes, which reduce the generalizability of the trained models. We propose a novel user satisfaction estimation approach which minimizes an adaptive multi-task loss function in order to jointly predict turn-level Response Quality labels provided by experts and explicit dialogue-level ratings provided by end users. The proposed BiLSTM based deep neural net model automatically weighs each turn\u2019s contribution towards the estimated dialogue-level rating, implicitly encodes temporal dependencies, and removes the need to hand-craft features. On dialogues sampled from 28 Alexa domains, two dialogue systems and three user groups, the joint dialogue-level satisfaction estimation model achieved up to an absolute 27% (0.43 -> 0.70) and 7% (0.63 -> 0.70) improvement in linear correlation performance over baseline deep neural net and benchmark Gradient boosting regression models, respectively.","authors":["Praveen Kumar Bodigutla","Aditya Tiwari","Spyros Matsoukas","Josep Valls-Vargas","Lazaros Polymenakos"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.347","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Joint Turn and Dialogue level User Satisfaction Estimation on Multi-Domain Conversations","tldr":"Dialogue level quality estimation is vital for optimizing data driven dialogue management. Current automated methods to estimate turn and dialogue level user satisfaction employ hand-crafted features and rely on complex annotation schemes, which redu...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.2889","presentation_id":"38940709","rocketchat_channel":"paper-scai-2889","speakers":"Praveen Kumar Bodigutla|Aditya Tiwari|Spyros Matsoukas|Josep Valls-Vargas|Lazaros Polymenakos","title":"Joint Turn and Dialogue level User Satisfaction Estimation on Multi-Domain Conversations"},{"content":{"abstract":"This paper presents a highly effective pipeline for passage retrieval in a conversational search setting. The pipeline comprises of two components: Conversational Term Selection (CTS) and Multi-View Reranking (MVR). CTS is responsible for performing the first-stage of passage retrieval. Given an input question, it uses a BERT-based classifier (trained with weak supervision) to de-contextualize the input by selecting relevant terms from the dialog history. Using the question and the selected terms, it issues a query to a search engine to perform the first-stage of passage retrieval. On the other hand, MVR is responsible for contextualized passage reranking. It first constructs multiple views of the information need embedded within an input question. The views are based on the dialog history and the top documents obtained in the first-stage of retrieval. It then uses each view to rerank passages using BERT (fine-tuned for passage ranking). Finally, MVR performs a fusion over the rankings produced by the individual views. Experiments show that the above combination improves first-state retrieval as well as the overall accuracy in a reranking pipeline. On the key metric of NDCG@3, the proposed combination achieves a relative performance improvement of 14.8% over the state-of-the-art baseline and is also able to surpass the Oracle.","authors":["Vaibhav Kumar","Jamie Callan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.354","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Making Information Seeking Easier: An Improved Pipeline for Conversational Search","tldr":"This paper presents a highly effective pipeline for passage retrieval in a conversational search setting. The pipeline comprises of two components: Conversational Term Selection (CTS) and Multi-View Reranking (MVR). CTS is responsible for performing ...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.2957","presentation_id":"38940710","rocketchat_channel":"paper-scai-2957","speakers":"Vaibhav Kumar|Jamie Callan","title":"Making Information Seeking Easier: An Improved Pipeline for Conversational Search"},{"content":{"abstract":"Non-task-oriented dialog models suffer from poor quality and non-diverse responses. To overcome limited conversational data, we apply Simulated Multiple Reference Training (SMRT; Khayrallah et al., 2020), and use a paraphraser to simulate multiple responses per training prompt. We find SMRT improves over a strong Transformer baseline as measured by human and automatic quality scores and lexical diversity. We also find SMRT is comparable to pretraining in human evaluation quality, and outperforms pretraining on automatic quality and lexical diversity, without requiring related-domain dialog data.","authors":["Huda Khayrallah","Jo\u00e3o Sedoc"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.403","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"SMRT Chatbots: Improving Non-Task-Oriented Dialog with Simulated Multiple Reference Training","tldr":"Non-task-oriented dialog models suffer from poor quality and non-diverse responses. To overcome limited conversational data, we apply Simulated Multiple Reference Training (SMRT; Khayrallah et al., 2020), and use a paraphraser to simulate multiple re...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.3361","presentation_id":"38940711","rocketchat_channel":"paper-scai-3361","speakers":"Huda Khayrallah|Jo\u00e3o Sedoc","title":"SMRT Chatbots: Improving Non-Task-Oriented Dialog with Simulated Multiple Reference Training"},{"content":{"abstract":"","authors":["Tba"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"TBA","tldr":null,"track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.paper1","presentation_id":"38940061","rocketchat_channel":"paper-scai-paper1","speakers":"Tba","title":"TBA"},{"content":{"abstract":"The dependency between an adequate question formulation and correct answer selection is a very intriguing but still underexplored area. In this paper, we show that question rewriting (QR) of the conversational context allows to shed more light on this phenomenon and also use it to evaluate robustness of different answer selection approaches. We introduce a simple framework that enables an automated analysis of the conversational question answering (QA) performance using question rewrites, and present the results of this analysis on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover sensitivity to question formulation of the popular state-of-the-art question answering approaches. Our results demonstrate that the reading comprehension model is insensitive to question formulation, while the passage ranking changes dramatically with a little variation in the input question. The benefit of QR is that it allows us to pinpoint and group such cases automatically. We show how to use this methodology to verify whether QA models are really learning the task or just finding shortcuts in the dataset, and better understand the frequent types of error they make.","authors":["Svitlana Vakulenko","Shayne Longpre","Zhucheng Tu","Raviteja Anantha"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.scai-1.2","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering","tldr":"The dependency between an adequate question formulation and correct answer selection is a very intriguing but still underexplored area. In this paper, we show that question rewriting (QR) of the conversational context allows to shed more light on thi...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.paper2","presentation_id":"38940062","rocketchat_channel":"paper-scai-paper2","speakers":"Svitlana Vakulenko|Shayne Longpre|Zhucheng Tu|Raviteja Anantha","title":"A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering"},{"content":{"abstract":"Sentence fusion is the task of joining related sentences into coherent text. Current training and evaluation schemes for this task are based on single reference ground-truths and do not account for valid fusion variants. We show that this hinders models from robustly capturing the semantic relationship between input sentences. To alleviate this, we present an approach in which ground-truth solutions are automatically expanded into multiple references via curated equivalence classes of connective phrases. We apply this method to a large-scale dataset and use the augmented dataset for both model training and evaluation. To improve the learning of semantic representation using multiple references, we enrich the model with auxiliary discourse classification tasks under a multi-tasking framework. Our experiments highlight the improvements of our approach over state-of-the-art models.","authors":["Eyal Ben-David","Orgad Keller","Eric Malmi","Idan Szpektor","Roi Reichart"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.135","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Semantically Driven Sentence Fusion: Modeling and Evaluation","tldr":"Sentence fusion is the task of joining related sentences into coherent text. Current training and evaluation schemes for this task are based on single reference ground-truths and do not account for valid fusion variants. We show that this hinders mod...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.paper3","presentation_id":"38940063","rocketchat_channel":"paper-scai-paper3","speakers":"Eyal Ben-David|Orgad Keller|Eric Malmi|Idan Szpektor|Roi Reichart","title":"Semantically Driven Sentence Fusion: Modeling and Evaluation"},{"content":{"abstract":"","authors":["Tba"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"TBA","tldr":null,"track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.paper4","presentation_id":"38940064","rocketchat_channel":"paper-scai-paper4","speakers":"Tba","title":"TBA"},{"content":{"abstract":"","authors":["Marco Guerini"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"TBA","tldr":null,"track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.paper5","presentation_id":"38940065","rocketchat_channel":"paper-scai-paper5","speakers":"Marco Guerini","title":"TBA"},{"content":{"abstract":"Understanding when and why neural ranking models fail for an IR task via error analysis is an important part of the research cycle. Here we focus on the challenges of (i) identifying categories of difficult instances (a pair of question and response candidates) for which a neural ranker is ineffective and (ii) improving neural ranking for such instances. To address both challenges we resort to slice-based learning for which the goal is to improve effectiveness of neural models for slices (subsets) of data. We address challenge (i) by proposing different slicing functions (SFs) that select slices of the dataset\u2014based on prior work we heuristically capture different failures of neural rankers. Then, for challenge (ii) we adapt a neural ranking model to learn slice-aware representations, i.e. the adapted model learns to represent the question and responses differently based on the model\u2019s prediction of which slices they belong to. Our experimental results (the source code and data are available at https://github.com/Guzpenha/slice_based_learning) across three different ranking tasks and four corpora show that slice-based learning improves the effectiveness by an average of 2% over a neural ranker that is not slice-aware.","authors":["Gustavo Penha","Claudia Hauff"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.scai-1.1","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Slice-Aware Neural Ranking","tldr":"Understanding when and why neural ranking models fail for an IR task via error analysis is an important part of the research cycle. Here we focus on the challenges of (i) identifying categories of difficult instances (a pair of question and response ...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.2020.scai-1.1","presentation_id":"","rocketchat_channel":"paper-scai-1","speakers":"Gustavo Penha|Claudia Hauff","title":"Slice-Aware Neural Ranking"},{"content":{"abstract":"Conversational Question Answering (ConvQA) is a Conversational Search task in a simplified setting, where an answer must be extracted from a given passage. Neural language models, such as BERT, fine-tuned on large-scale ConvQA datasets such as CoQA and QuAC have been used to address this task. Recently, Multi-Task Learning (MTL) has emerged as a particularly interesting approach for developing ConvQA models, where the objective is to enhance the performance of a primary task by sharing the learned structure across several related auxiliary tasks. However, existing ConvQA models that leverage MTL have not investigated the dynamic adjustment of the relative importance of the different tasks during learning, nor the resulting impact on the performance of the learned models. In this paper, we first study the effectiveness and efficiency of dynamic MTL methods including Evolving Weighting, Uncertainty Weighting, and Loss-Balanced Task Weighting, compared to static MTL methods such as the uniform weighting of tasks. Furthermore, we propose a novel hybrid dynamic method combining Abridged Linear for the main task with a Loss-Balanced Task Weighting (LBTW) for the auxiliary tasks, so as to automatically fine-tune task weighting during learning, ensuring that each of the task\u2019s weights is adjusted by the relative importance of the different tasks. We conduct experiments using QuAC, a large-scale ConvQA dataset. Our results demonstrate the effectiveness of our proposed method, which significantly outperforms both the single-task learning and static task weighting methods with improvements ranging from +2.72% to +3.20% in F1 scores. Finally, our findings show that the performance of using MTL in developing ConvQA model is sensitive to the correct selection of the auxiliary tasks as well as to an adequate balancing of the loss rates of these tasks during training by using LBTW.","authors":["Sarawoot Kongyoung","Craig Macdonald","Iadh Ounis"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.scai-1.3","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Multi-Task Learning using Dynamic Task Weighting for Conversational Question Answering","tldr":"Conversational Question Answering (ConvQA) is a Conversational Search task in a simplified setting, where an answer must be extracted from a given passage. Neural language models, such as BERT, fine-tuned on large-scale ConvQA datasets such as CoQA a...","track":"Search-Oriented Conversational AI (SCAI) 2"},"id":"WS-4.2020.scai-1.3","presentation_id":"","rocketchat_channel":"paper-scai-3","speakers":"Sarawoot Kongyoung|Craig Macdonald|Iadh Ounis","title":"Multi-Task Learning using Dynamic Task Weighting for Conversational Question Answering"}]
