[{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.1282.png","content":{"abstract":"Across languages, multiple consecutive adjectives modifying a noun (e.g.~``the big red dog'') follow certain unmarked ordering rules. While explanatory accounts have been put forward, much of the work done in this area has relied primarily on the intuitive judgment of native speakers, rather than on corpus data. We present the first purely corpus-driven model of multi-lingual adjective ordering in the form of a latent-variable model that can accurately order adjectives across 24 different languages, even when the training and testing languages are different. We utilize this novel statistical model to provide strong converging evidence for the existence of universal, cross-linguistic, hierarchical adjective ordering tendencies.","authors":["Jun Yen Leung","Guy Emerson","Ryan Cotterell"],"demo_url":"","keywords":["multi-lingual ordering","corpus-driven model","latent-variable model","statistical model"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.329","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7B","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.3181","main.3115","main.457","TACL.2013","main.820"],"title":"Investigating Cross-Linguistic Adjective Ordering Tendencies with a Latent-Variable Model","tldr":"Across languages, multiple consecutive adjectives modifying a noun (e.g.~``the big red dog'') follow certain unmarked ordering rules. While explanatory accounts have been put forward, much of the work done in this area has relied primarily on the int...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.1282","id":"main.1282","presentation_id":"38938880"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.1492.png","content":{"abstract":"Why do bilinguals switch languages within a sentence? The present observational study asks whether word surprisal and word entropy predict code-switching in bilingual written conversation. We describe and model a new dataset of Chinese-English text with 1476 clean code-switched sentences, translated back into Chinese.  The model includes known control variables together with word surprisal and word entropy. We found that word surprisal, but not entropy, is a significant predictor that explains code-switching above and beyond other well-known predictors. We also found sentence length to be a significant predictor, which has been related to sentence complexity. We propose high cognitive effort as a reason for code-switching, as it leaves fewer resources for inhibition of the alternative language. We also corroborate previous findings, but this time using a computational model of surprisal, a new language pair, and doing so for written language.","authors":["Jes\u00fas Calvillo","Le Fang","Jeremy Cole","David Reitter"],"demo_url":"","keywords":["code-switching","inhibition language","computational model","surprisal"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.330","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7B","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.3181","main.246","main.1613","main.767","main.3115"],"title":"Surprisal Predicts Code-Switching in Chinese-English Bilingual Text","tldr":"Why do bilinguals switch languages within a sentence? The present observational study asks whether word surprisal and word entropy predict code-switching in bilingual written conversation. We describe and model a new dataset of Chinese-English text w...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.1492","id":"main.1492","presentation_id":"38938918"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.1832.png","content":{"abstract":"Analyzing the evolution of dialects remains a challenging problem because contact phenomena hinder the application of the standard tree model. Previous statistical approaches to this problem resort to admixture analysis, where each dialect is seen as a mixture of latent ancestral populations. However, such ancestral populations are hardly interpretable in the context of the tree model. In this paper, we propose a probabilistic generative model that represents latent factors as geographical distributions. We argue that the proposed model has higher affinity with the tree model because a tree can alternatively be represented as a set of geographical distributions. Experiments involving synthetic and real data suggest that the proposed method is both quantitatively and qualitatively superior to the admixture model.","authors":["Yugo Murawaki"],"demo_url":"","keywords":["analyzing dialects","tree model","statistical approaches","admixture analysis"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.69","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1C","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.2894","main.3551","main.2886","main.2535","main.2076"],"title":"Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact","tldr":"Analyzing the evolution of dialects remains a challenging problem because contact phenomena hinder the application of the standard tree model. Previous statistical approaches to this problem resort to admixture analysis, where each dialect is seen as...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.1832","id":"main.1832","presentation_id":"38938993"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.2638.png","content":{"abstract":"Whereas there is a growing literature that probes neural language models to assess the degree to which they have latently acquired grammatical knowledge, little if any research has investigated their acquisition of discourse modeling ability.  We address this question by drawing on a rich psycholinguistic literature that has established how different contexts affect referential biases concerning who is likely to be referred to next.  The results reveal that, for the most part, the prediction behavior of neural language models does not resemble that of human language users.","authors":["Shiva Upadhye","Leon Bergen","Andrew Kehler"],"demo_url":"","keywords":["neural models","grammatical knowledge","referential biases","discourse ability"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.70","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1C","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.3115","main.1455","main.3181","main.2452","main.1613"],"title":"Predicting Reference: What do Language Models Learn about Discourse Models?","tldr":"Whereas there is a growing literature that probes neural language models to assess the degree to which they have latently acquired grammatical knowledge, little if any research has investigated their acquisition of discourse modeling ability.  We add...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.2638","id":"main.2638","presentation_id":"38939162"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.2851.png","content":{"abstract":"Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context (e.g., a simple declarative active-voice sentence) to a transformed context (e.g., an interrogative sentence). We test four models trained on the same dataset: an n-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision. We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.","authors":["Ethan Wilcox","Peng Qian","Richard Futrell","Ryosuke Kohita","Roger Levy","Miguel Ballesteros"],"demo_url":"","keywords":["learning outcomes","syntactic representations","neural models","n-gram baseline"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.375","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["TACL.2411","main.1892","main.1613","main.2430","main.76"],"title":"Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models","tldr":"Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this beha...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.2851","id":"main.2851","presentation_id":"38939210"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.3115.png","content":{"abstract":"Neural language models learn, to varying degrees of accuracy, the grammatical properties of natural languages. In this work, we investigate whether there are systematic sources of variation in the language models' accuracy. Focusing on subject-verb agreement and reflexive anaphora, we find that certain nouns are systematically understood better than others, an effect which is robust across grammatical tasks and different language models. Surprisingly, we find that across four orders of magnitude, corpus frequency is unrelated to a noun's performance on grammatical tasks. Finally, we find that a novel noun's grammatical properties can be few-shot learned from various types of training data. The results present a paradox: there should be less variation in grammatical performance than is actually observed.","authors":["Charles Yu","Ryan Sie","Nicolas Tedeschi","Leon Bergen"],"demo_url":"","keywords":["reflexive anaphora","grammatical tasks","neural models","language models"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.331","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7B","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.3181","main.1282","main.1613","main.2638","TACL.2013"],"title":"Word Frequency Does Not Predict Grammatical Knowledge in Language Models","tldr":"Neural language models learn, to varying degrees of accuracy, the grammatical properties of natural languages. In this work, we investigate whether there are systematic sources of variation in the language models' accuracy. Focusing on subject-verb a...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.3115","id":"main.3115","presentation_id":"38939271"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.3181.png","content":{"abstract":"Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -- a phenomenon known as verb bias. Here we introduce DAIS, a large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments.  We use this dataset, as well as an existing corpus of naturally occurring data, to evaluate how well recent neural language models capture human preferences. Results show that larger models perform better than smaller models, and transformer architectures (e.g. GPT-2) tend to out-perform recurrent architectures (e.g. LSTMs) even under comparable parameter and training settings. Additional analyses of internal feature representations suggest that transformers may better integrate specific lexical information with grammatical constructions.","authors":["Robert Hawkins","Takateru Yamakoshi","Thomas Griffiths","Adele Goldberg"],"demo_url":"","keywords":["grammatical construction","dais","neural models","transformer architectures"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.376","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.3115","TACL.2013","main.1613","main.1282","main.2363"],"title":"Investigating representations of verb bias in neural language models","tldr":"Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -- a phenomenon known as verb bias. ...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.3181","id":"main.3181","presentation_id":"38939281"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.373.png","content":{"abstract":"When speakers describe an image, they tend to look at objects before mentioning them. In this paper, we investigate such sequential cross-modal alignment by modelling the image description generation process computationally. We take as our starting point a state-of-the-art image captioning system and develop several model variants that exploit information from human gaze patterns recorded during language production. In particular, we propose the first approach to image description generation where visual processing is modelled sequentially. Our experiments and analyses confirm that better descriptions can be obtained by exploiting gaze-driven attention and shed light on human cognitive processes by comparing different ways of aligning the gaze modality with language production. We find that processing gaze data sequentially leads to descriptions that are better aligned to those produced by speakers, more diverse, and more natural---particularly when gaze is encoded with a dedicated recurrent component.","authors":["Ece Takmaz","Sandro Pezzelle","Lisa Beinborn","Raquel Fern\u00e1ndez"],"demo_url":"","keywords":["image process","language production","image generation","visual processing"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.377","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.2758","main.1402","main.1113","main.647","main.2702"],"title":"Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze","tldr":"When speakers describe an image, they tend to look at objects before mentioning them. In this paper, we investigate such sequential cross-modal alignment by modelling the image description generation process computationally. We take as our starting p...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.373","id":"main.373","presentation_id":"38938696"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.644.png","content":{"abstract":"Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language less clear---resulting in frequent miscommunication. For a language to be clear and efficiently encoded, we posit that the lexical ambiguity of a word type should correlate with how much information context provides about it, on average. To investigate whether this is the case, we operationalise the lexical ambiguity of a word as the entropy of meanings it can take, and provide two ways to estimate this---one which requires human annotation (using WordNet), and one which does not (using BERT), making it readily applicable to a large number of languages. We validate these measures by showing that, on six high-resource languages, there are significant Pearson correlations between our BERT-based estimate of ambiguity and the number of synonyms a word has in WordNet (e.g. $\\rho = 0.40$ in English). We then test our main hypothesis---that a word's lexical ambiguity should negatively correlate with its contextual uncertainty---and find significant correlations on all 18 typologically diverse languages we analyse. This suggests that, in the presence of ambiguity, speakers compensate by making contexts more informative.","authors":["Tiago Pimentel","Rowan Hall Maudslay","Damian Blasi","Ryan Cotterell"],"demo_url":"","keywords":["bert-based ambiguity","human annotation","lexical ambiguity","ambiguous words"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.328","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7B","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.1935","main.3224","main.2891","main.2363","main.2251"],"title":"Speakers Fill Lexical Semantic Gaps with Context","tldr":"Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language l...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.644","id":"main.644","presentation_id":"38938746"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/main.820.png","content":{"abstract":"Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes (e.g., noun-to-verb, verb-to-noun), and we apply this method to 37 languages. We find that contextualized embeddings not only capture human judgment of  class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology.","authors":["Bai Li","Guillaume Thomas","Yang Xu","Frank Rudzicz"],"demo_url":"","keywords":["linguistic typology","contextualized embeddings","deep models","word flexibility"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.71","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1C","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.3181","main.2363","main.2349","main.644","main.3224"],"title":"Word class flexibility: A deep contextualized approach","tldr":"Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"main.820","id":"main.820","presentation_id":"38938777"},{"card_image_path":"https://emnlp2020-public.s3.amazonaws.com/paper_images/TACL.2013.png","content":{"abstract":"We introduce The Benchmark of Linguistic Minimal Pairs (BLiMP), a challenge set for evaluating the linguistic knowledge of language models (LMs) on major grammatical phenomena in English. BLiMP consists of 67 individual datasets, each containing 1,000 minimal pairs, i.e. pairs of minimally different sentences that contrast in grammatical acceptability and isolate specific phenomenon in syntax, morphology, or semantics. We generate the data according to linguist-crafted grammar templates, and human aggregate agreement with the labels is 96.4%. We evaluate n-gram, LSTM, and Transformer (GPT-2 and TransformerXL) LMs by observing whether they assign a higher probability to the acceptable sentence in each minimal pair. We find that state-of-the-art models identify morphological contrasts related to agreement reliably, but they struggle with some subtle semantic and syntactic phenomena, such as negative polarity items and extraction islands.","authors":["Alex Warstadt","Alicia Parrish","Haokun Liu","Anhad Monananey","Wei Peng","Sheng-Fu Wang","Samuel Bowman"],"demo_url":"","keywords":["linguistic","blimp","lms","linguist-crafted templates"],"material":null,"paper_type":"TACL","pdf_url":"","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7B","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.3181","main.143","TACL.2141","main.2847","main.2179"],"title":"BLiMP: The Benchmark of Linguistic Minimal Pairs for English","tldr":"We introduce The Benchmark of Linguistic Minimal Pairs (BLiMP), a challenge set for evaluating the linguistic knowledge of language models (LMs) on major grammatical phenomena in English. BLiMP consists of 67 individual datasets, each containing 1,00...","track":"Linguistic Theories, Cognitive Modeling and Psycholinguistics"},"forum":"TACL.2013","id":"TACL.2013","presentation_id":"38939399"}]
