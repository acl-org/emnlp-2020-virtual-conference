[{"UID":"adobe","contacts":[{"email":"bui@adobe.com","name":"Trung Bui"}],"description":"With a team of world-class research scientists, engineers, artists, and designers, Adobe Research blends cutting-edge academic discovery with industry impact. Our researchers shape early-stage ideas into innovative technologies. Many of our discoveries are incorporated into Adobe\u2019s products, building the company\u2019s reputation as a leader in fostering new forms of creativity and in advancing document and content intelligence. Working across numerous domains, our researchers collaborate with colleagues at over 75 universities.\n","downloads":[{"label":"Adobe Research @ EMNLP 2020","website":"adobe_research_publications_emnlp_2020.pdf"}],"gather_times":{},"level":"Silver","logo":"adobe.png","logoontop":true,"name":"Adobe","rocketchat_channel":"sponsor-adobe","schedule":[{"duration":1.0,"label":"NLP Research at Adobe","start":"Wed, 18 Nov 2020 04:00:00 GMT"}],"website":"https://research.adobe.com/","youtube":"https://www.youtube.com/embed/9B9BCcqhyMk","zoom_link":"https://us02web.zoom.us/j/9525376582?pwd=QUNIZGVkVkRWTGtUV29JbGpuK3VrUT09","zoom_times":{"Wednesday, Nov 18":[["Wednesday, Nov 18 (04:00-05:00 GMT)","NLP Research at Adobe"]]}},{"UID":"amazon","contacts":[{"email":"emnlp2020@amazon.com","name":"Amazon EMNLP Team"}],"description":"At Amazon we fundamentally believe that scientific innovation is essential to being the most customer-centric company in the world. It's this ability to have an impact at scale that allows us to attract some of the brightest minds in artificial intelligence, NLP and related fields. Amazon\u2019s Machine Learning teams are looking forward to meeting you at EMNLP 2020. Come and build the future with us!","downloads":[{"label":"Amazon Research Brochure","website":"Research Brochure - EMNLP 2020.pdf"}],"gather_times":{},"level":"Diamond","logo":"amazon.png","logoontop":true,"name":"Amazon","resources":[{"label":"Submit Q&A for the talk - \"NLP & Conversational AI at Amazon\"","website":"https://amazon.qualtrics.com/jfe/form/SV_aXc8esOJztMAhtH"},{"label":"Amazon at EMNLP 2020","website":"https://www.amazon.science/conferences-and-events/emnlp-2020"},{"label":"Amazon Graduate Recruiting Team","website":"https://amazonemnlp2020.splashthat.com/"}],"rocketchat_channel":"sponsor-amazon","schedule":[{"duration":1.25,"label":"NLP & Conversational AI at Amazon - Panel Discussion and Q&A","start":"Thu, 19 Nov 2020 16:00:00 GMT"}],"website":"https://www.amazon.science/conferences-and-events/emnlp-2020?utm_campaign=events2020&utm_medium=recruiting&utm_source=collat&utm_content=event_page&utm_term=emnlp","youtube":"https://www.youtube.com/embed/H8dpdFTApgo","zoom_link":"https://us02web.zoom.us/j/4104890373?pwd=Wk9Bd1lSeDdPMk1IeEtuZGFmd2FVUT09","zoom_times":{"Thursday, Nov 19":[["Thursday, Nov 19 (16:00-17:15 GMT)","NLP & Conversational AI at Amazon - Panel Discussion and Q&A"]]}},{"UID":"apple","description":"Apple is a place where extraordinary people gather to do their best work. Our community is made up of every kind of individual: artists and designers, engineers and scientists, thinkers and doers. It\u2019s the diversity of those people and their ideas that inspires the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. And innovation at this level depends on people who represent the variety of the human experience and inspire us with their own fresh perspectives.\n","downloads":[{"label":"Job Card","website":"Apple- EMNLP Job Card.pdf"},{"label":"Chat with us","website":"Apple- EMNLP Chat With Us.pdf"}],"gather_times":{},"level":"Diamond","logo":"apple.png","logoontop":true,"name":"Apple","resources":[{"label":"Check in at our virtual booth","website":"http://applecorp.avature.net/registration?projectId=12927&source=Keep+in+Touch+-+UR+Portal"},{"label":"RSVP for our Meet Apple Virtual Event","website":"https://applecorp.avature.net/EMNLPrsvp"},{"label":"Learn more about our publications at EMNLP","website":"https://machinelearning.apple.com/updates/apple-at-emnlp-2020"},{"label":"Apply to full-time roles","website":"https://bit.ly/apple-emnlp2020"},{"label":"Apply to internship roles","website":"https://bit.ly/apple-emnlp2020-intern"}],"rocketchat_channel":"sponsor-apple","schedule":[{"duration":0.5,"label":"Meet Apple Virtual Event","start":"Wed, 18 Nov 2020 21:00:00 GMT"}],"website":"https://machinelearning.apple.com","youtube":"https://www.youtube.com/embed/vfkOZTjD06Y","zoom_link":"https://appleinc.webex.com/appleinc/onstage/g.php?MTID=ebeef7337dbef265460fe648f08c716d3","zoom_times":{"Wednesday, Nov 18":[["Wednesday, Nov 18 (21:00-21:30 GMT)","Meet Apple Virtual Event"]]}},{"UID":"babelscape","contacts":[{"email":"navigli@babelscape.com","name":"Roberto Navigli"},{"email":"dangeli@babelscape.com","name":"Lorenzo D'Angeli"}],"description":"**Babelscape** is a high-tech Sapienza startup company founded in 2016\nfocused on **multilingual Natural Language Processing** with the main\ngoal of **enabling multilinguality and text understanding** in customers\u2019\napplications which deal with text in different ways.\nThanks to technological transfer from the internationally renowned\nNatural Language Processing research group headed by *prof. Roberto\nNavigli* at the Sapienza University of Rome, **winner of two European\nResearch Council grants and of several international awards**, the\ncompany places itself on the market with very high professional\nprofiles and the ability to tailor its solutions to the customers' needs.\nThe company's core mission is to **overcome the language barriers** by\nenabling the automatic processing of text **independently of the input\nlanguage**, and distilling and aggregating the information extracted across\nlanguages by means of a unified large-scale multilingual knowledge repository\nand **semantically-enhanced text comprehension systems**.\n","downloads":[{"label":"Products and Services","website":"babelscape-resource-brochure_allproducts_1_.pdf"}],"gather_times":{},"level":"Silver","logo":"babelscape.png","logoontop":true,"name":"Babelscape","resources":[{"label":"Job Openings","website":"https://babelscape.com/jobs"}],"rocketchat_channel":"sponsor-babelscape","schedule":[{"duration":1,"label":"WordAtlas: the largest multilingual semantic network, encyclopedic dictionary and knowledge repository for multilingual applications","start":"Mon, 16 Nov 2020 16:00:00 GMT"},{"duration":1,"label":"NLP pipeline: a full-fledged multilingual natural language pipeline","start":"Mon, 16 Nov 2020 17:00:00 GMT"},{"duration":1,"label":"Comprehendo: multilingual word sense disambiguation and entity linking","start":"Tue, 17 Nov 2020 09:00:00 GMT"},{"duration":1,"label":"Extraggo: extracting the key concepts and entities from text and connecting them to a multilingual knowledge graph","start":"Tue, 17 Nov 2020 12:00:00 GMT"},{"duration":1,"label":"NLP pipeline: a full-fledged multilingual natural language pipeline","start":"Tue, 17 Nov 2020 16:00:00 GMT"},{"duration":1,"label":"WordAtlas: the largest multilingual semantic network, encyclopedic dictionary and knowledge repository for multilingual applications","start":"Wed, 18 Nov 2020 09:00:00 GMT"},{"duration":1,"label":"Extraggo: extracting the key concepts and entities from text and connecting them to a multilingual knowledge graph","start":"Wed, 18 Nov 2020 10:00:00 GMT"},{"duration":1,"label":"Comprehendo: multilingual word sense disambiguation and entity linking","start":"Wed, 18 Nov 2020 16:00:00 GMT"}],"website":"https://babelscape.com/","youtube":"https://www.youtube.com/embed/FC-OJRXwoig","zoom_link":"https://us02web.zoom.us/j/5693515745?pwd=bUdHdkVnQkd3R2tDeHR3Qi96UHA3Zz09","zoom_times":{"Monday, Nov 16":[["Monday, Nov 16 (16:00-17:00 GMT)","WordAtlas: the largest multilingual semantic network, encyclopedic dictionary and knowledge repository for multilingual applications"],["Monday, Nov 16 (17:00-18:00 GMT)","NLP pipeline: a full-fledged multilingual natural language pipeline"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (09:00-10:00 GMT)","Comprehendo: multilingual word sense disambiguation and entity linking"],["Tuesday, Nov 17 (12:00-13:00 GMT)","Extraggo: extracting the key concepts and entities from text and connecting them to a multilingual knowledge graph"],["Tuesday, Nov 17 (16:00-17:00 GMT)","NLP pipeline: a full-fledged multilingual natural language pipeline"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (09:00-10:00 GMT)","WordAtlas: the largest multilingual semantic network, encyclopedic dictionary and knowledge repository for multilingual applications"],["Wednesday, Nov 18 (10:00-11:00 GMT)","Extraggo: extracting the key concepts and entities from text and connecting them to a multilingual knowledge graph"],["Wednesday, Nov 18 (16:00-17:00 GMT)","Comprehendo: multilingual word sense disambiguation and entity linking"]]}},{"UID":"baidu","contacts":[{"email":"caiqianwei@baidu.com","name":"Qianwei Cai"},{"email":"changyue@baidu.com","name":"Yue Chang"}],"description":"Founded on January 1, 2000, Baidu is the world\u2019s largest Chinese language Internet search provider, the largest knowledge and information centered Internet platform company in China, and a world-leading artificial intelligence (AI) platform company. Robin Li, Baidu\u2019s co-founder, chairman, and chief executive officer, was awarded a U.S. patent for his development of the Rankdex site-scoring algorithm for search engine page rankings, making China one of only four countries in the world that has developed core search engine technology, along with the United States, Russia, and South Korea.\n","gather_times":{},"grouped_publications":{"Findings":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.35.png","content":{"abstract":"Tensor-based fusion methods have been proven effective in multimodal fusion tasks. However, existing tensor-based methods make a poor use of the fine-grained temporal dynamics of multimodal sequential features. Motivated by this observation, this paper proposes a novel multimodal fusion method called Fine-Grained Temporal Low-Rank Multimodal Fusion (FT-LMF). FT-LMF correlates the features of individual time steps between multiple modalities, while it involves multiplications of high-order tensors in its calculation. This paper further proposes Dual Low-Rank Multimodal Fusion (Dual-LMF) to reduce the computational complexity of FT-LMF through low-rank tensor approximation along dual dimensions of input features. Dual-LMF is conceptually simple and practically effective and efficient. Empirical studies on benchmark multimodal analysis tasks show that our proposed methods outperform the state-of-the-art tensor-based fusion methods with a similar computational complexity.","authors":["Tao Jin","Siyu Huang","Yingming Li","Zhongfei Zhang"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.35","program":"findings","sessions":[],"similar_paper_uids":["findings.35"],"title":"Dual Low-Rank Multimodal Fusion","tldr":"Tensor-based fusion methods have been proven effective in multimodal fusion tasks. However, existing tensor-based methods make a poor use of the fine-grained temporal dynamics of multimodal sequential features. Motivated by this observation, this pap...","track":"Findings of EMNLP"},"forum":"findings.35","id":"findings.35","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.444.png","content":{"abstract":"Continuous efforts have been devoted to language understanding (LU) for conversational queries with the fast and wide-spread popularity of voice assistants. In this paper, we first study the LU problem in the spatial domain, which is a critical problem for providing location-based services by voice assistants but is without in-depth investigation in existing studies. Spatial domain queries have several unique properties making them be more challenging for language understanding than common conversational queries, including lexical-similar but diverse intents and highly ambiguous words. Thus, a special tailored LU framework for spatial domain queries is necessary. To the end, a dataset was extracted and annotated based on the real-life queries from a voice assistant service. We then proposed a new multi-task framework that jointly learns the intent detection and entity linking tasks on the with invented hierarchical intent detection method and triple-scoring mechanism for entity linking. A specially designed spatial GCN is also utilized to model spatial context information among entities. We have conducted extensive experimental evaluations with state-of-the-art entity linking and intent detection methods, which demonstrated that can outperform all baselines with a significant margin.","authors":["Lei Zhang","Runze Wang","Jingbo Zhou","Jingsong Yu","Zhenhua Ling","Hui Xiong"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.444","program":"findings","sessions":[],"similar_paper_uids":["findings.444"],"title":"Joint Intent Detection and Entity Linking on Spatial Domain Queries","tldr":"Continuous efforts have been devoted to language understanding (LU) for conversational queries with the fast and wide-spread popularity of voice assistants. In this paper, we first study the LU problem in the spatial domain, which is a critical probl...","track":"Findings of EMNLP"},"forum":"findings.444","id":"findings.444","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.73.png","content":{"abstract":"Event extraction, which aims to identify event triggers of pre-defined event types and their arguments of specific roles, is a challenging task in NLP. Most traditional approaches formulate this task as classification problems, with event types or argument roles taken as golden labels. Such approaches fail to model rich interactions among event types and arguments of different roles, and cannot generalize to new types or roles. This work proposes a new paradigm that formulates event extraction as multi-turn question answering. Our approach, MQAEE, casts the extraction task into a series of reading comprehension problems, by which it extracts triggers and arguments successively from a given sentence. A history answer embedding strategy is further adopted to model question answering history in the multi-turn process. By this new formulation, MQAEE makes full use of dependency among arguments and event types, and generalizes well to new types with new argument roles. Empirical results on ACE 2005 shows that MQAEE outperforms current state-of-the-art, pushing the final F1 of argument extraction to 53.4% (+2.0%). And it also has a good generalization ability, achieving competitive performance on 13 new event types even if trained only with a few samples of them.","authors":["Fayuan Li","Weihua Peng","Yuguang Chen","Quan Wang","Lu Pan","Yajuan Lyu","Yong Zhu"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.73","program":"findings","sessions":[],"similar_paper_uids":["findings.73"],"title":"Event Extraction as Multi-turn Question Answering","tldr":"Event extraction, which aims to identify event triggers of pre-defined event types and their arguments of specific roles, is a challenging task in NLP. Most traditional approaches formulate this task as classification problems, with event types or ar...","track":"Findings of EMNLP"},"forum":"findings.73","id":"findings.73","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.69.png","content":{"abstract":"One of the biggest bottlenecks in building accurate, high coverage neural open IE systems is the need for large labelled corpora. The diversity of open domain corpora and the variety of natural language expressions further exacerbate this problem. In this paper, we propose a syntactic and semantic-driven learning approach, which can learn neural open IE models without any human-labelled data by leveraging syntactic and semantic knowledge as noisier, higher-level supervision. Specifically, we first employ syntactic patterns as data labelling functions and pretrain a base model using the generated labels. Then we propose a syntactic and semantic-driven reinforcement learning algorithm, which can effectively generalize the base model to open situations with high accuracy. Experimental results show that our approach significantly outperforms the supervised counterparts, and can even achieve competitive performance to supervised state-of-the-art (SoA) model.","authors":["Jialong Tang","Yaojie Lu","Hongyu Lin","Xianpei Han","Le Sun","Xinyan Xiao","Hua Wu"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.69","program":"findings","sessions":[],"similar_paper_uids":["findings.69"],"title":"Syntactic and Semantic-driven Learning for Open Information Extraction","tldr":"One of the biggest bottlenecks in building accurate, high coverage neural open IE systems is the need for large labelled corpora. The diversity of open domain corpora and the variety of natural language expressions further exacerbate this problem. In...","track":"Findings of EMNLP"},"forum":"findings.69","id":"findings.69","presentation_id":null}],"Long":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3236.png","content":{"abstract":"Balancing accuracy and latency is a great challenge for simultaneous translation. To achieve high accuracy, the model usually needs to wait for more streaming text before translation, which results in increased latency. However, keeping low latency would probably hurt accuracy. Therefore, it is essential to segment the ASR output into appropriate units for translation. Inspired by human interpreters, we propose a novel adaptive segmentation policy for simultaneous translation. The policy learns to segment the source text by considering possible translations produced by the translation model, maintaining consistency between the segmentation and translation. Experimental results on Chinese-English and German-English translation show that our method achieves a better accuracy-latency trade-off over recently proposed state-of-the-art methods.","authors":["Ruiqing Zhang","Chuanqiang Zhang","Zhongjun He","Hua Wu","Haifeng Wang"],"demo_url":"","keywords":["simultaneous translation","translation","segmentation","chinese-english translation"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.178","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 09:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z5D","start_time":"Tue, 17 Nov 2020 08:00:00 GMT"}],"similar_paper_uids":["main.2661","main.1402","demo.111","main.1572","main.2100"],"title":"Learning Adaptive Segmentation Policy for Simultaneous Translation","tldr":"Balancing accuracy and latency is a great challenge for simultaneous translation. To achieve high accuracy, the model usually needs to wait for more streaming text before translation, which results in increased latency. However, keeping low latency w...","track":"Machine Translation and Multilinguality"},"forum":"main.3236","id":"main.3236","presentation_id":"38939292"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3064.png","content":{"abstract":"Neural Document-level Multi-aspect Sentiment Classification (DMSC) usually requires a lot of manual aspect-level sentiment annotations, which is time-consuming and laborious. As document-level sentiment labeled data are widely available from online service, it is valuable to perform DMSC with such free document-level annotations. To this end, we propose a novel Diversified Multiple Instance Learning Network (D-MILN), which is able to achieve aspect-level sentiment classification with only document-level weak supervision. Specifically, we connect aspect-level and document-level sentiment by formulating this problem as multiple instance learning, providing a way to learn aspect-level classifier from the back propagation of document-level supervision. Two diversified regularizations are further introduced in order to avoid the overfitting on document-level signals during training. Diversified textual regularization encourages the classifier to select aspect-relevant snippets, and diversified sentimental regularization prevents the aspect-level sentiments from being overly consistent with document-level sentiment. Experimental results on TripAdvisor and BeerAdvocate datasets show that D-MILN remarkably outperforms recent weakly-supervised baselines, and is also comparable to the supervised method.","authors":["Yunjie Ji","Hao Liu","Bolei He","Xinyan Xiao","Hua Wu","Yanhua Yu"],"demo_url":"","keywords":["neural","aspect-level classification","dmsc","diversified"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.570","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g4E","start_time":"Wed, 18 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1675","main.3185","main.3286","main.1289","main.1023"],"title":"Diversified Multiple Instance Learning for Document-Level Multi-Aspect Sentiment Classification","tldr":"Neural Document-level Multi-aspect Sentiment Classification (DMSC) usually requires a lot of manual aspect-level sentiment annotations, which is time-consuming and laborious. As document-level sentiment labeled data are widely available from online s...","track":"Sentiment Analysis, Stylistic Analysis, and Argument Mining"},"forum":"main.3064","id":"main.3064","presentation_id":"38939261"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.349.png","content":{"abstract":"Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question/SQL pairs. Our new dataset has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via human-computer collaboration. The basic idea is automatically generating SQL queries based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and data statistics of DuSQL. Moreover, we present and compare performance of several open-source text-to-SQL parsers with minor modification to accommodate Chinese, including a simple yet effective extension to IRNet for handling calculation SQL queries.","authors":["Lijie Wang","Ao Zhang","Kun Wu","Ke Sun","Zhenghua Li","Hua Wu","Min Zhang","Haifeng Wang"],"demo_url":"","keywords":["text-to-sql parsing","cross-domain task","manually questions","sql queries"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.562","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g4F","start_time":"Wed, 18 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1866","main.3682","main.3544","main.3507","main.1784"],"title":"DuSQL: A Large-Scale and Pragmatic Chinese Text-to-SQL Dataset","tldr":"Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the c...","track":"Semantics: Sentence-level Semantics, Textual Inference and Other areas"},"forum":"main.349","id":"main.349","presentation_id":"38938688"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.110.png","content":{"abstract":"Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the lack of extensive training data and professional structural knowledge neglect. As an effort, we first collect a large scale medical multi-choice question dataset (more than 21k instances) for the National Licensed Pharmacist Examination in China. It is a challenging medical examination with a passing rate of less than 14.2% in 2018. Then we propose a novel reading comprehension model KMQA, which can fully exploit the structural medical knowledge (i.e., medical knowledge graph) and the reference medical plain text (i.e., text snippets retrieved from reference books). The experimental results indicate that the KMQA outperforms existing competitive models with a large margin and passes the exam with 61.8% accuracy rate on the test set.","authors":["Dongfang Li","Baotian Hu","Qingcai Chen","Weihua Peng","Anqi Wang"],"demo_url":"","keywords":["national examination","medical examination","large-scale models","reading model"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.111","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1F","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1631","main.1923","main.2630","main.748","main.1159"],"title":"Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text","tldr":"Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the ...","track":"NLP Applications"},"forum":"main.110","id":"main.110","presentation_id":""},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3497.png","content":{"abstract":"Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence  without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution -- Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.","authors":["Mingming Sun","Wenyue Hua","Zoey Liu","Xin Wang","Kangjie Zheng","Ping Li"],"demo_url":"","keywords":["inference operations","oie algorithms","featured strategies","pipeline"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.167","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 09:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z5A","start_time":"Tue, 17 Nov 2020 08:00:00 GMT"}],"similar_paper_uids":["demo.48","main.1179","demo.72","main.3453","main.2342"],"title":"A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression","tldr":"Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE...","track":"Information Extraction"},"forum":"main.3497","id":"main.3497","presentation_id":"38939349"}],"Short":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.2818.png","content":{"abstract":"This paper designs a Monolingual Lexicon Induction task and observes that two factors accompany the degraded accuracy of bilingual lexicon induction for rare words. First, a diminishing margin between similarities in low frequency regime, and secondly, exacerbated hubness at low frequency. Based on the observation, we further propose two methods to address these two factors, respectively. The larger issue is hubness. Addressing that improves induction accuracy significantly, especially for low-frequency words.","authors":["Jiaji Huang","Xingyu Cai","Kenneth Church"],"demo_url":"","keywords":["monolingual task","bilingual induction","low regime","hubness"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.100","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1B","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1901","main.3181","main.2891","main.865","main.3115"],"title":"Improving Bilingual Lexicon Induction for Low Frequency Words","tldr":"This paper designs a Monolingual Lexicon Induction task and observes that two factors accompany the degraded accuracy of bilingual lexicon induction for rare words. First, a diminishing margin between similarities in low frequency regime, and secondl...","track":"Machine Learning for NLP"},"forum":"main.2818","id":"main.2818","presentation_id":"38939203"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3621.png","content":{"abstract":"Slot filling and intent detection are two main tasks in spoken language understanding (SLU) system. In this paper, we propose a novel non-autoregressive model named SlotRefine for joint intent detection and slot filling. Besides, we design a novel two-pass iteration mechanism to handle the uncoordinated slots problem caused by conditional independence of non-autoregressive model. Experiments demonstrate that our model significantly outperforms previous models in slot filling task, while considerably speeding up the decoding (up to x10.77). In-depth analysis show that 1) pretraining schemes could further enhance our model; 2) two-pass mechanism indeed remedy the uncoordinated slots.","authors":["Di Wu","Liang Ding","Fan Lu","Jian Xie"],"demo_url":"","keywords":["slot filling","intent detection","spoken system","joint detection"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.152","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1E","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.3257","main.3051","main.1225","main.1432","main.557"],"title":"SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection and Slot Filling","tldr":"Slot filling and intent detection are two main tasks in spoken language understanding (SLU) system. In this paper, we propose a novel non-autoregressive model named SlotRefine for joint intent detection and slot filling. Besides, we design a novel tw...","track":"Dialog and Interactive Systems"},"forum":"main.3621","id":"main.3621","presentation_id":"38939377"}]},"level":"Platinum","logo":"baidu.png","logoontop":true,"name":"Baidu","publications":["main.3236","main.3064","main.349","main.2818","main.110","main.3621","main.3497","findings.35","findings.444","findings.73","findings.69"],"resources":[{"label":"Brochure of Baidu Natural Language Processing","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Brochure_of_Baidu_Natural_Language_Processing.pdf"},{"label":"Brochure of Baidu Knowledge Graph","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Brochure_of_Baidu_Knowledge_Graph.pdf"},{"label":"Brochure of Baidu Research","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Brochure_of_Baidu_Research.pdf"},{"label":"Brochure of PaddlePaddle","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Brochure_of_PaddlePaddle.pdf"},{"label":"Introduction to Baidu's Natural Language Processing","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Introduction_to_Baidu's_Natural_Language_Processing.ppsx"},{"label":"Baidu @ EMNLP 2020","website":"https://fanyiapp.cdn.bcebos.com/cms/misc/Baidu_Schedule.pdf"}],"rocketchat_channel":"sponsor-baidu","schedule":[{"duration":1,"label":"Chat with Baidu Researchers and Recruiters","start":"Tue, 17 Nov 2020 03:00:00 GMT"},{"duration":1,"label":"Chat with Baidu Researchers and Recruiters","start":"Tue, 17 Nov 2020 08:00:00 GMT"},{"duration":1,"label":"Chat with Baidu Researchers and Recruiters","start":"Wed, 18 Nov 2020 03:00:00 GMT"},{"duration":1,"label":"Chat with Baidu Researchers and Recruiters","start":"Wed, 18 Nov 2020 08:00:00 GMT"}],"website":"https://www.baidu.com/","youtube":"https://www.youtube.com/embed/JJq2MWRIPBQ","youtubes":["https://www.youtube.com/embed/iBqfajFcSzo","https://www.youtube.com/embed/hrlz42GQHgQ","https://www.youtube.com/embed/Y7bEdGHmeWg"],"zoom_link":"https://us02web.zoom.us/j/4301994498?pwd=UzRTSkFQUlVGOTIrVFgvaGFFQnZhZz09","zoom_times":{"Tuesday, Nov 17":[["Tuesday, Nov 17 (03:00-04:00 GMT)","Chat with Baidu Researchers and Recruiters"],["Tuesday, Nov 17 (08:00-09:00 GMT)","Chat with Baidu Researchers and Recruiters"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (03:00-04:00 GMT)","Chat with Baidu Researchers and Recruiters"],["Wednesday, Nov 18 (08:00-09:00 GMT)","Chat with Baidu Researchers and Recruiters"]]}},{"UID":"bloomberg","contacts":[{"email":"cortiz20@bloomberg.net","name":"Chevonne Ortiz"},{"email":"mkulkarni24@bloomberg.net","name":"Mayank Kulkarni"},{"email":"cteichmann1@bloomberg.net","name":"Christoph Teichmann"}],"description":"Bloomberg is building the world's most trusted information network for financial professionals. Our 6,000+ engineers, developers, and data scientists are dedicated to advancing and building new solutions and systems for the Bloomberg Terminal and other products in order to solve complex, real-world problems. Improving search and discovery of relevant content, functionality, and insights are critical focus areas for Bloomberg. To this end, we use Machine Learning, Deep Learning, Natural Language Processing, Information Retrieval, and Knowledge Graph technology across Bloomberg. Applications include search, semantic parsing for question answering, recommendation systems, topic clustering and classification, sentiment analysis, anomaly detection in time series and a variety of other problems. For example, our AI researchers are building machine learning models and neural networks to quickly understand and respond to major world events in order to predict when or how breaking business news will impact company stock prices and move markets \u2013 and why.","gather_schedule":[{"end":"Mon, 16 Nov 2020 20:00:00 GMT","label":"Bloomberg researcher(s) and recruiting at the booth","start":"Mon, 16 Nov 2020 16:00:00 GMT"},{"duration":1,"label":"Bloomberg researcher(s) at the booth","start":"Tue, 17 Nov 2020 10:00:00 GMT"},{"end":"Tue, 17 Nov 2020 21:00:00 GMT","label":"Bloomberg researcher(s) and recruiting at the booth","start":"Tue, 17 Nov 2020 16:00:00 GMT"},{"end":"Wed, 18 Nov 2020 11:00:00 GMT","label":"Bloomberg researcher(s) and recruiting at the booth","start":"Wed, 18 Nov 2020 09:00:00 GMT"},{"end":"Wed, 18 Nov 2020 21:00:00 GMT","label":"Bloomberg researcher(s) and recruiting at the booth","start":"Wed, 18 Nov 2020 16:00:00 GMT"}],"gather_times":{"Monday, Nov 16":[["Monday, Nov 16 (16:00-20:00 GMT)","Bloomberg researcher(s) and recruiting at the booth"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (10:00-11:00 GMT)","Bloomberg researcher(s) at the booth"],["Tuesday, Nov 17 (16:00-21:00 GMT)","Bloomberg researcher(s) and recruiting at the booth"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (09:00-11:00 GMT)","Bloomberg researcher(s) and recruiting at the booth"],["Wednesday, Nov 18 (16:00-21:00 GMT)","Bloomberg researcher(s) and recruiting at the booth"]]},"level":"Diamond","logo":"bloomberg.png","logoontop":true,"name":"Bloomberg","rocketchat_channel":"sponsor-bloomberg","schedule":[{"duration":1,"label":"Introduction to Bloomberg","start":"Mon, 16 Nov 2020 17:00:00 GMT"}],"website":"https://www.TechAtBloomberg.com","youtube":"https://www.youtube.com/embed/2ZlZD-fvuhc","zoom_link":"https://us02web.zoom.us/j/8948229064?pwd=dlM2cCtCM1cyVjFPWEFhQW5ST3hRZz09","zoom_times":{"Monday, Nov 16":[["Monday, Nov 16 (17:00-18:00 GMT)","Introduction to Bloomberg"]]}},{"UID":"bytedance","contacts":[{"email":"alexanderlindblom@bytedance.com","name":"Alexander Lindblom"}],"description":"Founded in 2012, ByteDance is a technology company operating a range of content platforms that inform, educate, entertain, and inspire people across language, culture. Dedicated to building global platforms of creation and interaction, ByteDance now has over 60,000 global employees and a portfolio of applications available in over 150 markets and 75 languages, including Toutiao, Douyin, Xigua Video, TikTok, Helo, Lark, and more. Our mission: Inspire Creativity and Enrich Life.\n","gather_times":{},"gdrive":"https://drive.google.com/file/d/1uF7loSpxI2mpUCi7hGUN7komGT3ehxMo/preview","grouped_publications":{"Findings":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.441.png","content":{"abstract":"Active learning for sentence understanding aims at discovering informative unlabeled data for annotation and therefore reducing the demand for labeled data. We argue that the typical uncertainty sampling method for active learning is time-consuming and can hardly work in real-time, which may lead to ineffective sample selection. We propose adversarial uncertainty sampling in discrete space (AUSDS) to retrieve informative unlabeled samples more efficiently. AUSDS maps sentences into latent space generated by the popular pre-trained language models, and discover informative unlabeled text samples for annotation via adversarial attack. The proposed approach is extremely efficient compared with traditional uncertainty sampling with more than 10x speedup. Experimental results on five datasets show that AUSDS outperforms strong baselines on effectiveness.","authors":["Dongyu Ru","Jiangtao Feng","Lin Qiu","Hao Zhou","Mingxuan Wang","Weinan Zhang","Yong Yu","Lei Li"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.441","program":"findings","sessions":[],"similar_paper_uids":["findings.441"],"title":"Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete Space","tldr":"Active learning for sentence understanding aims at discovering informative unlabeled data for annotation and therefore reducing the demand for labeled data. We argue that the typical uncertainty sampling method for active learning is time-consuming a...","track":"Findings of EMNLP"},"forum":"findings.441","id":"findings.441","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.115.png","content":{"abstract":"Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMC, an efficient method to generate high likelihood sentences with respect to a pre-trained language model while satisfying the constraints. Our approach is highly flexible, requires no task-specific train- ing, and leverages efficient constraint satisfaction solving techniques. To better handle the combinatorial constraints, a tree search algorithm is embedded into the proposal process of the Markov Chain Monte Carlo (MCMC) to explore candidates that satisfy more constraints. Compared to existing MCMC approaches, our sampling approach has a better mixing performance. Experiments show that TSMC achieves consistent and significant improvement on multiple language generation tasks.","authors":["Maosen Zhang","Nan Jiang","Lei Li","Yexiang Xue"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.115","program":"findings","sessions":[],"similar_paper_uids":["findings.115"],"title":"Language Generation via Combinatorial Constraint Satisfaction: A Tree Search Enhanced Monte-Carlo Approach","tldr":"Generating natural language under complex constraints is a principled formulation towards controllable text generation. We present a framework to allow specification of combinatorial constraints for sentence generation. We propose TSMC, an efficient ...","track":"Findings of EMNLP"},"forum":"findings.115","id":"findings.115","presentation_id":null}],"Long":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3635.png","content":{"abstract":"Pre-trained contextual representations like BERT have achieved great success in natural language processing. However, the sentence embeddings from the pre-trained language models without fine-tuning have been found to poorly capture semantic meaning of sentences. In this paper, we argue that the semantic information in the BERT embeddings is not fully exploited. We first reveal the theoretical connection between the masked language model pre-training objective and the semantic similarity task theoretically, and then analyze the BERT sentence embeddings empirically. We find that BERT always induces a non-smooth anisotropic semantic space of sentences, which harms its performance of semantic similarity. To address this issue, we propose to transform the anisotropic sentence embedding distribution to a smooth and isotropic Gaussian distribution through normalizing flows that are learned with an unsupervised objective. Experimental results show that our proposed BERT-flow method obtains significant performance gains over the state-of-the-art sentence embeddings on a variety of semantic textual similarity tasks. The code is available at \\url{https://github.com/bohanli/BERT-flow}.","authors":["Bohan Li","Hao Zhou","Junxian He","Mingxuan Wang","Yiming Yang","Lei Li"],"demo_url":"","keywords":["natural processing","semantic task","semantic tasks","pre-trained representations"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.733","program":"main","sessions":[{"end_time":"Thu, 19 Nov 2020 00:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z15C","start_time":"Wed, 18 Nov 2020 23:00:00 GMT"}],"similar_paper_uids":["main.3358","main.3609","TACL.2411","main.3093","main.2851"],"title":"On the Sentence Embeddings from Pre-trained Language Models","tldr":"Pre-trained contextual representations like BERT have achieved great success in natural language processing. However, the sentence embeddings from the pre-trained language models without fine-tuning have been found to poorly capture semantic meaning ...","track":"Semantics: Sentence-level Semantics, Textual Inference and Other areas"},"forum":"main.3635","id":"main.3635","presentation_id":"38939378"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3688.png","content":{"abstract":"We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then \ufb01ne-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves signi\ufb01cant performance improvement compared to directly training on those target pairs. It is the \ufb01rst time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github. com/linzehui/mRASP.","authors":["Zehui Lin","Xiao Pan","Mingxuan Wang","Xipeng Qiu","Jiangtao Feng","Hao Zhou","Lei Li"],"demo_url":"","keywords":["machine mt","mt","rich mt","universal model"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.210","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 12:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g2E","start_time":"Tue, 17 Nov 2020 10:00:00 GMT"}],"similar_paper_uids":["main.1680","main.522","main.852","main.267","TACL.2107"],"title":"Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information","tldr":"We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-tra...","track":"Machine Translation and Multilinguality"},"forum":"main.3688","id":"main.3688","presentation_id":"38939388"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.158.png","content":{"abstract":"Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across paragraphs. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN), a method to recognize such relations for long paragraphs. GAIN constructs two graphs, a heterogeneous mention-level graph (MG) and an entity-level graph (EG). The former captures complex interaction among different mentions and the latter aggregates mentions underlying for the same entities. Based on the graphs we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at https://github.com/PKUnlp-icler/GAIN.","authors":["Shuang Zeng","Runxin Xu","Baobao Chang","Lei Li"],"demo_url":"","keywords":["document-level extraction","sentence-level extraction","graph network","graph"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.127","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1D","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.327","main.574","main.2761","main.1706","main.1648"],"title":"Double Graph Based Reasoning for Document-level Relation Extraction","tldr":"Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across paragraphs. In this paper, we propose Graph Aggrega...","track":"Information Extraction"},"forum":"main.158","id":"main.158","presentation_id":"38938659"}],"Workshop":[{"content":{"abstract":"This paper describes our submission systems for VolcTrans for WMT20 shared news translation task. We participated in 8 translation directions. Our basic systems are based on Transformer <cit.>, into which we also employed new architectures (bigger or deeper Transformers, dynamic convolution). The final systems include text pre-process, subword(a.k.a. BPE<cit.>), baseline model training, iterative back-translation, model ensemble, knowledge distillation and multilingual pre-training.","authors":["Liwei Wu","Xiao Pan","Zehui Lin","Yaoming ZHU","Mingxuan Wang","Lei Li"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.statmt.org/wmt20/pdf/2020.wmt-1.33.pdf","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"The Volctrans Machine Translation System for WMT20","tldr":"This paper describes our submission systems for VolcTrans for WMT20 shared news translation task. We participated in 8 translation directions. Our basic systems are based on Transformer <cit.>, into which we also employed new architectures (bigger or...","track":"Fifth Conference on Machine Translation (WMT20)"},"id":"WS-2.59","presentation_id":"38939581","rocketchat_channel":"paper-wmt-59","speakers":"Liwei Wu|Xiao Pan|Zehui Lin|Yaoming ZHU|Mingxuan Wang|Lei Li","title":"The Volctrans Machine Translation System for WMT20"},{"content":{"abstract":"In this paper, we describe our submissions to the WMT20 shared task on parallel corpus filtering and alignment for low-resource conditions. The task requires the participants to align potential parallel sentence pairs out of the given document pairs, and score them so that low-quality pairs can be filtered. Our system, Volctrans, is made of two modules, i.e., a mining module and a scoring module. Based on the word alignment model, the mining mod- ule adopts an iterative mining strategy to extract latent parallel sentences. In the scoring module, an XLM-based scorer provides scores, followed by reranking mechanisms and ensemble. Our submissions outperform the baseline by 3.x/2.x and 2.x/2.x for km-en and ps-en on From Scratch/Fine-Tune conditions.","authors":["Runxin Xu","Zhuo Zhi","Jun Cao","Mingxuan Wang","Lei Li"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.statmt.org/wmt20/pdf/2020.wmt-1.112.pdf","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Volctrans Parallel Corpus Filtering System for WMT 2020","tldr":"In this paper, we describe our submissions to the WMT20 shared task on parallel corpus filtering and alignment for low-resource conditions. The task requires the participants to align potential parallel sentence pairs out of the given document pairs,...","track":"Fifth Conference on Machine Translation (WMT20)"},"id":"WS-2.2","presentation_id":"38939544","rocketchat_channel":"paper-wmt-2","speakers":"Runxin Xu|Zhuo Zhi|Jun Cao|Mingxuan Wang|Lei Li","title":"Volctrans Parallel Corpus Filtering System for WMT 2020"}]},"level":"Gold","logo":"bytedance.png","logoontop":true,"name":"ByteDance","publications":["main.3635","main.3688","main.158","findings.441","findings.115","WS-2.59","WS-2.2"],"resources":[{"label":"Career opportunities","website":"https://drive.google.com/file/d/1cxQ0QBMO2PX4knbhMI3RSCVQciQdS585/view?usp=sharing"},{"label":"Coding Camp","website":"https://drive.google.com/file/d/11ELUag3A_c5WReIga-tQzRGR_EepRk22/view?usp=sharing"},{"label":"Joint Research","website":"https://drive.google.com/file/d/1_1XeJn-LgWbcpIiXMiIZKw_SCj36p_La/view?usp=sharing"}],"rocketchat_channel":"sponsor-bytedance","website":"https://www.bytedance.com/en/","youtube":"https://www.youtube.com/watch?v=V51B44WHs98&feature=youtu.be","zoom_link":"https://us02web.zoom.us/j/2786437534?pwd=T2VMSGZEUGtJY1loRDlHQUROYWlPdz09","zoom_times":{}},{"UID":"deepmind","channel":"DeepMind","contacts":[{"email":"dm-emnlp-2020-enquiries@google.com","name":"General Enquiries / Resume Drop"}],"description":"Artificial intelligence could be one of humanity's most useful inventions. DeepMind aims to build advanced AI to expand our knowledge and find solutions to thousands of problems.\n\nWe\u2019re a team of scientists, engineers, machine learning experts and more, working together to advance the state of the art in artificial intelligence. We use our technologies for widespread public benefit and scientific discovery, and collaborate with others on critical challenges, ensuring safety and ethics are the highest priority.\n\nWe have a track record of breakthroughs in fundamental AI research, published in journals like Nature, Science, and more. Our programs have learned to diagnose eye diseases as effectively as the world\u2019s top doctors, to save 30% of the energy used to keep data centres cool, and to make state of the art predictions of the complex 3D shapes of proteins - which could one day transform how drugs are invented.\n\nDeepMind was founded in London in 2010, and we joined forces with Google in 2014 to accelerate our work. Since then, our community has expanded to include teams in Alberta, Montreal, Paris, and Mountain View in California.\n","downloads":[{"label":"Language Team Overview","website":"DeepMind_Language-Team-Overview.pdf"},{"label":"Careers Leaflet - Engineering and Games","website":"DeepMind_Eng-and-Games.pdf"},{"label":"Careers Leaflet - Operations","website":"DeepMind_Operations.pdf"},{"label":"Careers Leaflet - Research","website":"DeepMind_Research.pdf"},{"label":"Careers Leaflet - Science and DeepMind for Google","website":"DeepMind_Science-and-DeepMind-for-Google.pdf"}],"gather_schedule":[{"duration":1.0,"label":"Chat with the DeepMind Language Team","start":"Mon, 16 Nov 2020 17:00:00 GMT"},{"duration":1.0,"label":"Chat with the DeepMind Language Team","start":"Tue, 17 Nov 2020 17:00:00 GMT"}],"gather_times":{"Monday, Nov 16":[["Monday, Nov 16 (17:00-18:00 GMT)","Chat with the DeepMind Language Team"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (17:00-18:00 GMT)","Chat with the DeepMind Language Team"]]},"grouped_publications":{"Findings":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.106.png","content":{"abstract":"Unsupervised speech representation learning has shown remarkable success at finding representations that correlate with phonetic structures and improve downstream speech recognition performance. However, most research has been focused on evaluating the representations in terms of their ability to improve the performance of speech recognition systems on read English (e.g. Wall Street Journal and LibriSpeech). This evaluation methodology overlooks two important desiderata that speech representations should have: robustness to domain shifts and transferability to other languages. In this paper we learn representations from up to 8000 hours of diverse and noisy speech data and evaluate the representations by looking at their robustness to domain shifts and their ability to improve recognition performance in many languages. We find that our representations confer significant robustness advantages to the resulting recognition systems: we see significant improvements in out-of-domain transfer relative to baseline feature sets and the features likewise provide improvements in 25 phonetically diverse languages.","authors":["Kazuya Kawakami","Luyu Wang","Chris Dyer","Phil Blunsom","Aaron van den Oord"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.106","program":"findings","sessions":[],"similar_paper_uids":["findings.106"],"title":"Learning Robust and Multilingual Speech Representations","tldr":"Unsupervised speech representation learning has shown remarkable success at finding representations that correlate with phonetic structures and improve downstream speech recognition performance. However, most research has been focused on evaluating t...","track":"Findings of EMNLP"},"forum":"findings.106","id":"findings.106","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.7.png","content":{"abstract":"Advances in language modeling architectures and the availability of large text corpora have driven progress in automatic text generation. While this results in models capable of generating coherent texts, it also prompts models to internalize social biases present in the training corpus. This paper aims to quantify and reduce a particular type of bias exhibited by language models: bias in the sentiment of generated text. Given a conditioning context (e.g., a writing prompt) and a language model, we analyze if (and how) the sentiment of the generated text is affected by changes in values of sensitive attributes (e.g., country names, occupations, genders) in the conditioning context using a form of counterfactual evaluation. We quantify sentiment bias by adopting individual and group fairness metrics from the fair machine learning literature, and demonstrate that large-scale models trained on two different corpora (news articles, and Wikipedia) exhibit considerable levels of bias. We then propose embedding and sentiment prediction-derived regularization on the language model\u2019s latent representations. The regularizations improve fairness metrics while retaining comparable levels of perplexity and semantic similarity.","authors":["Po-Sen Huang","Huan Zhang","Ray Jiang","Robert Stanforth","Johannes Welbl","Jack Rae","Vishal Maini","Dani Yogatama","Pushmeet Kohli"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.7","program":"findings","sessions":[],"similar_paper_uids":["findings.7"],"title":"Reducing Sentiment Bias in Language Models via Counterfactual Evaluation","tldr":"Advances in language modeling architectures and the availability of large text corpora have driven progress in automatic text generation. While this results in models capable of generating coherent texts, it also prompts models to internalize social ...","track":"Findings of EMNLP"},"forum":"findings.7","id":"findings.7","presentation_id":null}],"Long":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1901.png","content":{"abstract":"Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. As a result, they perform poorly or fail completely on non-isomorphic spaces. Such non-isomorphism has been hypothesised to result from typological differences between languages. In this work, we ask whether non-isomorphism is also crucially a sign of degenerate word vector spaces. We present a series of experiments across diverse languages which show that variance in performance across language pairs is not only due to typological differences, but can mostly be attributed to the size of the monolingual resources available, and to the properties and duration of monolingual training (e.g. \"under-training\").","authors":["Ivan Vuli\u0107","Sebastian Ruder","Anders S\u00f8gaard"],"demo_url":"","keywords":["aligning spaces","monolingual training","vector spaces","non-isomorphic spaces"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.257","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 12:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g2L","start_time":"Tue, 17 Nov 2020 10:00:00 GMT"}],"similar_paper_uids":["main.2131","main.865","main.2891","main.410","main.447"],"title":"Are All Good Word Vector Spaces Isomorphic?","tldr":"Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. As a result, they perform poorly or fail completely on non-isomorphic spaces. Such non-isomorphism has been hypothesised to resu...","track":"Interpretability and Analysis of Models for NLP"},"forum":"main.1901","id":"main.1901","presentation_id":"38939005"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1817.png","content":{"abstract":"Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AxCell, an automatic machine learning pipeline for extracting results from papers. AxCell uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing methods, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training models for results extraction, and a dataset for evaluating the performance of models on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. Code is available on GitHub.","authors":["Marcin Kardas","Piotr Czapla","Pontus Stenetorp","Sebastian Ruder","Sebastian Riedel","Ross Taylor","Robert Stojnic"],"demo_url":"","keywords":["machine learning","table subtask","extraction","results extraction"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.692","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g5D","start_time":"Wed, 18 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.3646","main.1669","main.1977","demo.72","main.3470"],"title":"AxCell: Automatic Extraction of Results from Machine Learning Papers","tldr":"Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AxCell, an automatic machine learning pipeline for extracting results from papers. AxCell uses severa...","track":"Information Extraction"},"forum":"main.1817","id":"main.1817","presentation_id":"38938992"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1455.png","content":{"abstract":"Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle  tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful.  Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.","authors":["Yonatan Bisk","Ari Holtzman","Jesse Thomason","Jacob Andreas","Yoshua Bengio","Joyce Chai","Mirella Lapata","Angeliki Lazaridou","Jonathan May","Aleksandr Nisnevich","Nicolas Pinto","Joseph Turian"],"demo_url":"","keywords":["language research","tasks","linguistic communication","natural processing"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.703","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g5F","start_time":"Wed, 18 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.2638","main.3115","main.2363","main.1130","main.1613"],"title":"Experience Grounds Language","tldr":"Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle  tasks after b...","track":"Language Grounding to Vision, Robotics and Beyond"},"forum":"main.1455","id":"main.1455","presentation_id":"38938907"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1803.png","content":{"abstract":"The main goal behind state-of-the-art pre-trained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pre-training. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pre-trained multilingual model to a new language. MAD-X outperforms the state of the art in cross lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Our code and adapters are available at AdapterHub.ml.","authors":["Jonas Pfeiffer","Ivan Vuli\u0107","Iryna Gurevych","Sebastian Ruder"],"demo_url":"","keywords":["transfer","pre-training","cross transfer","named recognition"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.617","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 18:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z14A","start_time":"Wed, 18 Nov 2020 17:00:00 GMT"}],"similar_paper_uids":["main.74","main.1379","main.3688","main.871","main.2500"],"title":"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer","tldr":"The main goal behind state-of-the-art pre-trained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to l...","track":"Machine Translation and Multilinguality"},"forum":"main.1803","id":"main.1803","presentation_id":"38938991"}],"Short":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.2583.png","content":{"abstract":"Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. In recent literature, two general methods partially counter this phenomenon: Supervised Selfplay (S2P) and Seeded Iterated Learning (SIL). While S2P jointly trains interactive and supervised losses to counter the drift, SIL changes the training dynamics to prevent language drift from occurring. In this paper, we first highlight their respective weaknesses, i.e., late-stage training collapses and higher negative likelihood when evaluated on human corpus. Given these observations, we introduce Supervised Seeded Iterated Learning (SSIL) to combine both methods to minimize their respective weaknesses. We then show the effectiveness of \\algo in the language-drift translation game.","authors":["Yuchen Lu","Soumye Singhal","Florian Strub","Olivier Pietquin","Aaron Courville"],"demo_url":"","keywords":["language drift","language-drift game","language models","word-based agents"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.325","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 17:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z7A","start_time":"Tue, 17 Nov 2020 16:00:00 GMT"}],"similar_paper_uids":["main.2389","main.74","main.128","main.1892","main.2851"],"title":"Supervised Seeded Iterated Learning for Interactive Language Learning","tldr":"Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. ...","track":"Dialog and Interactive Systems"},"forum":"main.2583","id":"main.2583","presentation_id":"38939148"}],"demo":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//demo.71.png","content":{"abstract":"The current modus operandi in NLP involves downloading and fine-tuning pre-trained models consisting of millions or billions of parameters. Storing and sharing such large trained models is expensive, slow, and time-consuming, which impedes progress towards more general and versatile NLP methods that learn from and for many tasks. Adapters---small learnt bottleneck layers inserted within each layer of a pre-trained model--- ameliorate this issue by avoiding full fine-tuning of the entire model. However, sharing and integrating adapter layers is not straightforward. We propose AdapterHub, a framework that allows dynamic \"stiching-in\" of pre-trained adapters for different tasks and languages. The framework, built on top of the popular HuggingFace Transformers library, enables extremely easy and quick adaptations of state-of-the-art pre-trained models (e.g., BERT, RoBERTa, XLM-R) across tasks and languages. Downloading, sharing, and training adapters is as seamless as possible using minimal changes to the training scripts and a specialized infrastructure. Our framework enables scalable and easy access to sharing of task-specific models, particularly in low-resource scenarios. AdapterHub includes all recent adapter architectures and can be found at AdapterHub.ml","authors":["Jonas Pfeiffer","Andreas R\u00fcckl\u00e9","Clifton Poth","Aishwarya Kamath","Ivan Vuli\u0107","Sebastian Ruder","Kyunghyun Cho","Iryna Gurevych"],"demo_url":"","keywords":["modus operandi","downloading models","downloading","nlp methods"],"material":"","paper_type":"demo","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-demos.7","program":"demo","sessions":[{"end_time":"Tue, 17 Nov 2020 12:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g2M","start_time":"Tue, 17 Nov 2020 10:00:00 GMT"}],"similar_paper_uids":["main.1803","main.1485","main.1552","demo.60","main.1130"],"title":"AdapterHub: A Framework for Adapting Transformers","tldr":"The current modus operandi in NLP involves downloading and fine-tuning pre-trained models consisting of millions or billions of parameters. Storing and sharing such large trained models is expensive, slow, and time-consuming, which impedes progress t...","track":"System Demonstrations"},"forum":"demo.71","id":"demo.71","presentation_id":null}]},"levels":["Platinum","Diversity & Inclusion: Champion"],"logo":"deep_mind.png","logoontop":true,"name":"DeepMind","publications":["main.1901","main.1817","main.1455","findings.106","main.1803","findings.7","main.2583","demo.71"],"rocketchat_channel":"sponsor-deepmind","website":"https://deepmind.com/","youtube":"https://www.youtube.com/embed/koEWIEHTopo","zoom_link":"https://us02web.zoom.us/j/8516356683?pwd=cDlPZTFWN1grdXpqN1dRZndLTXduZz09","zoom_times":{}},{"UID":"facebook","description":"Facebook AI works with the research community to advance artificial intelligence. Our areas of research cover many fields including but not limited to speech and audio, conversational AI, ranking and recommendations, and computer vision. Facebook AI is comprised of two core divisions \u2013 fundamental research (FAIR) and applied research. FAIR seeks to further our fundamental understanding in both new and existing domains, covering the full spectrum of topics related to AI, with the mission of advancing the state-of-the-art of AI through open research for the benefit of all. Facebook AI Applied Research engages in cutting-edge research that can improve and power new product experiences at huge scale for our community. Facebook AI is built on the key principles of openness, collaboration, excellence, and scale. We believe the latest advancements in AI should be published and open-sourced for the community. We work openly with internal and external partners to collaborate and share knowledge. We believe there is no shortage of new areas to explore in AI, and our researchers focus on the projects we believe will have the most positive impact on society. Finally, our research must account for both large scale data and computation needs in order to bring the benefits of AI to more people and improve accessibility. \"If our mission and work intrigue you, Facebook AI is always looking to hire the best talent to our globally based teams. For information about open roles and how to apply, please visit https://ai.facebook.com/join-us/\"","downloads":[{"label":"JOB CARD","website":"Facebook-Job_Card.pdf"}],"gather_times":{},"level":"Platinum","logo":"facebook.jpg","logoontop":true,"name":"Facebook","resources":[{"label":"RECRUITMENT SCHEDULE","website":"https://docs.google.com/document/d/1N3HfH4zUODZjzfHvBmm3hsJOrrjeN1P-8OuNA3n9V10/edit?usp=sharing"}],"rocketchat_channel":"sponsor-facebook","website":"https://ai.facebook.com/","youtube":"https://www.youtube.com/embed/eiqUzieHu8o","zoom_link":"https://us02web.zoom.us/j/6908152693?pwd=bVBYREhwNzZkMDNReHVyU1dUMTJiUT09","zoom_times":{}},{"UID":"google_research","description":"Natural Language Processing (NLP) research at Google focuses on algorithms that apply at scale, across languages, and across domains. Our systems are used in numerous ways across Google, impacting user experience in search, mobile, apps, ads, translate and more. Our syntactic systems predict part-of-speech tags for each word in a given sentence, as well as morphological features such as gender and number. They also label relationships between words, such as subject, object, modification, and others. We focus on efficient algorithms that leverage large amounts of unlabeled data, and recently have incorporated neural net technology. On the semantic side, we identify entities in free text, label them with types (such as person, location, or organization), cluster mentions of those entities within and across documents (coreference resolution), and resolve the entities to the Knowledge Graph. To learn more about the research we\u2019re presenting at EMNLP 2020, check out our [Accepted Papers](https://goo.gle/EMNLP-Accepted-Papers) and [Workshops and Tutorials](https://goo.gle/EMNLP-Workshops-Tutorials). Interested in seeing more of our latest research developments and meeting the people behind our innovations? Be sure to explore our [Google AI blog](https://ai.googleblog.com/) and [Google Research website](https://research.google/).\n\nOur RocketChat schedule is: (i) On Nov. 16 (Mon), Nov. 18 (Wed) and Nov 20 (Fri): GMT: 9-10AM, 2-3PM, 4-5PM, 9-10PM, 10-11PM / PST: 1-2AM, 6-7AM, 11AM-12PM, 1-2PM, 2-3PM; (ii) On Nov 19 (Thu): GMT: 9-10AM, 4-5PM, 9-10PM, 10-11PM / PST: 1-2AM, 11AM-12PM, 1-2PM, 2-3PM.\n","gather_times":{},"level":"Diamond","logo":"google_research.png","logoontop":true,"name":"Google Research","resources":[{"label":"Google Accepted Papers","website":"http://goo.gle/EMNLP-Accepted-Papers"},{"label":"Google Accepted Workshop & Tutorials","website":"http://goo.gle/EMNLP-Workshops-Tutorials"},{"label":"Googlers on Organizing Committees","website":"http://goo.gle/EMNLP-Organizing-Committees"},{"label":"Chat With Us","website":"http://goo.gle/EMNLP-Chat-With-Us"},{"label":"Demos","website":"http://goo.gle/EMNLP-Demos"},{"label":"Diversity and Inclusion at Google","website":"http://goo.gle/EMNLP-Diversity"},{"label":"Careers at Google","website":"http://goo.gle/EMNLP-Careers"}],"rocketchat_channel":"sponsor-google-research","schedule":[{"duration":1.0,"label":"Hiring Q&A with Google Recruiters","start":"Tue, 17 Nov 2020 16:00:00 GMT"},{"duration":1.0,"label":"Google Research Demo - QED: An Extensible, Structured Framework for Explainable Question Answering","start":"Tue, 17 Nov 2020 17:30:00 GMT"},{"duration":1.0,"label":"Hiring Q&A with Google Recruiters","start":"Wed, 18 Nov 2020 16:00:00 GMT"},{"duration":1.0,"label":"Google Research Demo - The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP","start":"Wed, 18 Nov 2020 17:30:00 GMT"}],"website":"http://goo.gle/EMNLP-Homepage","youtube":"https://www.youtube.com/embed/EvfziohbbnE","zoom_link":"https://meet.google.com/ugx-seds-jpt","zoom_times":{"Tuesday, Nov 17":[["Tuesday, Nov 17 (16:00-17:00 GMT)","Hiring Q&A with Google Recruiters"],["Tuesday, Nov 17 (17:30-18:30 GMT)","Google Research Demo - QED: An Extensible, Structured Framework for Explainable Question Answering"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (16:00-17:00 GMT)","Hiring Q&A with Google Recruiters"],["Wednesday, Nov 18 (17:30-18:30 GMT)","Google Research Demo - The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP"]]}},{"UID":"grammarly","contacts":[{"email":"dana.schafer@grammarly.com","name":"Dana Schafer"},{"email":"chad.mills@grammarly.com","name":"Chad Mills"}],"description":"Grammarly develops an AI-based writing assistant that helps 30 million people every day write more clearly and effectively in English. In building a product that scales across multiple platforms and devices\u2014including a web editor, native desktop apps, an iPad app, mobile keyboards, add-ins for Microsoft Office, and browser extensions\u2014Grammarly works to empower users whenever and wherever they communicate.\n\nGrammarly\u2019s writing assistant is powered by advanced AI. We\u2019re building a product that delivers sophisticated communication suggestions, adapts to individual users, and scales across the internet. Using a variety of innovative approaches\u2014including advanced machine learning and deep learning\u2014we consistently break new ground in natural language processing (NLP) research to deliver unrivaled assistance in our product offerings.\n\nAcross offices in San Francisco, Kyiv, New York, and Vancouver, Grammarly\u2019s values-driven team is growing\u2014to support our expanding user base and to continue developing our writing assistant into a truly comprehensive communication partner.\n\nCheck out our technical blog, where Grammarly\u2019s engineers and researchers discuss the technical challenges they\u2019re tackling: [Here](https://bit.ly/3eptm6P).\n\nExplore open roles: [Here](https://bit.ly/2TMICkN).\n","downloads":[{"label":"Job Openings","website":"grammarly_About.pdf"},{"label":"Publications","website":"grammarly_publications.pdf"},{"label":"Grammarly's Tech Blog","website":"grammarly_tech_blog.pdf"},{"label":"Adversarial Grammatical Error Correction","website":"grammarly_paper.pdf"}],"gather_times":{},"level":"Gold","logo":"grammarly.png","logoontop":true,"name":"Grammarly","resources":[{"label":"Life at Grammarly","website":"https://bit.ly/325nydB"},{"label":"Technology at Grammarly","website":"https://bit.ly/35Zl8hM"}],"rocketchat_channel":"sponsor-grammarly","schedule":[{"duration":1,"label":"Live Q&A: Learn more about how the team is growing with Grammarly technical recruiter Dana Schafer","start":"Mon, 16 Nov 2020 18:00:00 GMT"},{"duration":1,"label":"Live Q&A: Learn more about the day-to-day on Grammarly\u2019s computational linguistics team with Masha Ivenskaya","start":"Tue, 17 Nov 2020 18:00:00 GMT"},{"duration":1,"label":"Paper presentation: Vipul Raheja will present his paper \u201cAdversarial Grammatical Error Correction,\u201d followed by a Q&A session","start":"Tue, 17 Nov 2020 20:00:00 GMT"},{"duration":1,"label":"Live Q&A: Learn more about the day-to-day on Grammarly\u2019s research team with Chad Mills, Grammarly\u2019s manager of applied research and engineering","start":"Wed, 18 Nov 2020 18:00:00 GMT"}],"website":"https://www.grammarly.com/jobs/technology?utm_source=conference&utm_medium=website&utm_campaign=emnlp2020","youtube":"https://www.youtube.com/embed/Dlq-knQpBzs","zoom_link":"https://us02web.zoom.us/j/6934399329?pwd=UTRoL3hia29GMHNkaFhPQ2dBU2hNdz09","zoom_times":{"Monday, Nov 16":[["Monday, Nov 16 (18:00-19:00 GMT)","Live Q&A: Learn more about how the team is growing with Grammarly technical recruiter Dana Schafer"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (18:00-19:00 GMT)","Live Q&A: Learn more about the day-to-day on Grammarly\u2019s computational linguistics team with Masha Ivenskaya"],["Tuesday, Nov 17 (20:00-21:00 GMT)","Paper presentation: Vipul Raheja will present his paper \u201cAdversarial Grammatical Error Correction,\u201d followed by a Q&A session"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (18:00-19:00 GMT)","Live Q&A: Learn more about the day-to-day on Grammarly\u2019s research team with Chad Mills, Grammarly\u2019s manager of applied research and engineering"]]}},{"UID":"hitachi,_ltd","contacts":[{"email":"rdg.recruit@rdgml.intra.hitachi.co.jp","name":"Yuko Tamura"}],"description":"Hitachi is contributing to the expansion of social innovation business through R&D on digital technologies such as data science, media processing, AI, service computing, and computing architecture to achieve safety and support efficient societal infrastructure","downloads":[{"label":"Recuitment Flyers","website":"Hitachi_R_D_Recruit_2020.pdf"}],"gather_times":{},"level":"Silver","logo":"hitachi.png","logoontop":true,"name":"Hitachi, Ltd","resources":[{"label":"Research in Hitachi","website":"http://www.hitachi.com/rd/research/digitaltechnology/index.html"}],"rocketchat_channel":"sponsor-hitachi","schedule":[{"duration":0.5,"label":"Not set yet","start":"Tue, 07 Jul 2020 17:00:00 GMT"}],"website":"https://www.hitachi.com/rd/index.html","youtube":"https://www.youtube.com/embed/Z9kfpJV8R2o","zoom_link":"https://us02web.zoom.us/j/8208787597?pwd=dzVyTmExZUNLaDZYdUlydDdmQlFQUT09","zoom_times":{"Tuesday, Jul 07":[["Tuesday, Jul 07 (17:00-17:30 GMT)","Not set yet"]]}},{"UID":"isi","channel":"example_sponsor","gather_times":{},"landingpage":"https://www.isi.edu/","level":"Bronze","logo":"isi.png","name":"ISI","rocketchat_channel":"sponsor-isi","website":"https://www.isi.edu","zoom_link":"https://us02web.zoom.us/j/6976149518?pwd=Wk9XbDA4ODNpem1VUjVWYndNRlBCUT09","zoom_times":{}},{"UID":"megagon_labs","contacts":[{"email":"makiko@megagon.ai","name":"Makiko Shiino"},{"email":"vivian@megagon.ai","name":"Vivian Li"}],"description":"Since 2016, Megagon Labs (formerly Recruit Institute of Technology) has conducted top-notch research and build technologies in Mountain View and Tokyo.  We are making impacts through the worldwide services and products of the Recruit Group by empowering people to make their best decision.  Our research focuses are in the broad areas of Artificial Intelligence, Data Management, and Natural Language Processing.","gather_schedule":[{"duration":3,"label":"Meet Megagon Labs at GatherTown","start":"Mon, 16 Nov 2020 20:00:00 GMT"}],"gather_times":{"Monday, Nov 16":[["Monday, Nov 16 (20:00-23:00 GMT)","Meet Megagon Labs at GatherTown"]]},"grouped_publications":{"Findings":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.181.png","content":{"abstract":"Data programming aims to reduce the cost of curating training data by encoding domain knowledge as labeling functions over source data. As such it not only requires domain expertise but also programming experience, a skill that many subject matter experts lack. Additionally, generating functions by enumerating rules is not only time consuming but also inherently difficult, even for people with programming experience. In this paper we introduce Ruler, an interactive system that synthesizes labeling rules using span-level interactive demonstrations over document examples. Ruler is a first-of-a-kind implementation of data programming by demonstration (DPBD). This new framework aims to relieve users from the burden of writing labeling functions, enabling them to focus on higher-level semantic analysis, such as identifying relevant signals for the labeling task. We compare Ruler with conventional data programming through a user study conducted with 10 data scientists who were asked to create labeling functions for sentiment and spam classification tasks. Results show Ruler is easier to learn and to use, and that it offers higher overall user-satisfaction while providing model performances comparable to those achieved by conventional data programming.","authors":["Sara Evensen","Chang Ge","Cagatay Demiralp"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.181","program":"findings","sessions":[],"similar_paper_uids":["findings.181"],"title":"Ruler: Data Programming by Demonstration for Document Labeling","tldr":"Data programming aims to reduce the cost of curating training data by encoding domain knowledge as labeling functions over source data. As such it not only requires domain expertise but also programming experience, a skill that many subject matter ex...","track":"Findings of EMNLP"},"forum":"findings.181","id":"findings.181","presentation_id":null}],"Long":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.595.png","content":{"abstract":"Subjectivity is the expression of internal opinions or beliefs which cannot be objectively observed or verified, and has been shown to be important for sentiment analysis and word-sense disambiguation. Furthermore, subjectivity is an important aspect of user-generated data. In spite of this, subjectivity has not been investigated in contexts where such data is widespread, such as in question answering (QA). We develop a new dataset which allows us to investigate this relationship. We find that subjectivity is an important feature in the case of QA, albeit with more intricate interactions between subjectivity and QA performance than found in previous work on sentiment analysis. For instance, a subjective question may or may not be associated with a subjective answer. We release an English QA dataset (SubjQA) based on customer reviews, containing subjectivity annotations for questions and answer spans across 6 domains.","authors":["Johannes Bjerva","Nikita Bhutani","Behzad Golshan","Wang-Chiew Tan","Isabelle Augenstein"],"demo_url":"","keywords":["sentiment analysis","word-sense disambiguation","question qa","qa"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.442","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3G","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.1023","main.3186","main.1675","main.2973","main.1540"],"title":"SubjQA: A Dataset for Subjectivity and Review Comprehension","tldr":"Subjectivity is the expression of internal opinions or beliefs which cannot be objectively observed or verified, and has been shown to be important for sentiment analysis and word-sense disambiguation. Furthermore, subjectivity is an important aspect...","track":"Question Answering"},"forum":"main.595","id":"main.595","presentation_id":"38938734"}]},"level":"Platinum","logo":"megagon.png","logoontop":true,"name":"Megagon Labs","publications":["main.595","findings.181"],"resources":[{"label":"Megagon Labs","website":"https://megagon.ai/"},{"label":"Career opportunities","website":"https://megagon.ai/jobs/"},{"label":"Megagon Labs Publications","website":"https://megagon.ai/publications/"}],"rocketchat_channel":"sponsor-megagon-labs","schedule":[{"duration":0.5,"label":"Meet our Researchers","start":"Tue, 17 Nov 2020 20:00:00 GMT"},{"duration":0.5,"label":"Discussion about Ruler: Data Programming by Demonstration for Document Labeling","start":"Tue, 17 Nov 2020 20:30:00 GMT"}],"website":"http://www.megagon.ai/","youtube":null,"zoom_link":"https://us02web.zoom.us/j/4214315981?pwd=K3JHVTMxUFFQU0M3bmJiRWo3SmZWZz09","zoom_times":{"Tuesday, Nov 17":[["Tuesday, Nov 17 (20:00-20:30 GMT)","Meet our Researchers"],["Tuesday, Nov 17 (20:30-21:00 GMT)","Discussion about Ruler: Data Programming by Demonstration for Document Labeling"]]}},{"UID":"naver","contacts":[{"email":"dl_info@naverlabs.com","name":"NAVER LABS Europe"},{"email":"dl_nlp_emnlp_2020@navercorp.com","name":"NAVER (Korea)"}],"description":"NAVER Corporation is Korea's premier Internet company and a global leader in online services such as NAVER search (30M DAU), LINE messaging (164MAU), and WEBTOON (62M MAU). NAVER is continuously focussed on the future and in seamlessly connecting the physical and digital worlds through advanced technology. Its AI and Robotics research in Asia and Europe are fundamental to creating this future. NAVER invests over 25 percent of annual revenue in R&D yet innovation is but one core value. NAVER promotes diversity on the internet, respects and connects people helping them to share knowledge, create communities and preserve culture.\n","gather_times":{},"level":"Silver","logo":"naver.png","logoontop":true,"name":"NAVER","resources":[{"label":"List of publications at EMNLP2020","website":"https://europe.naverlabs.com/emnlp2020/#1592572802695-16c77470-538f"},{"label":"Interactive Sessions","website":"https://europe.naverlabs.com/emnlp2020/#1593607137225-16acdb52-d404"},{"label":"Job Openings","website":"https://europe.naverlabs.com/emnlp2020/#1593600341618-a651a831-f5ac"},{"label":"Overview of NAVER and NAVER LABS Europe","website":"https://europe.naverlabs.com/emnlp2020/#1604669457089-576c9a34-2233"}],"rocketchat_channel":"sponsor-naver","schedule":[{"end":"Wed, 18 Nov 2020 09:45:00 GMT","label":"Machine Translation (Papago), Document Information Extraction and Conversational AI at NAVER","start":"Wed, 18 Nov 2020 09:00:00 GMT"},{"end":"Wed, 18 Nov 2020 16:30:00 GMT","label":"NLP research at NAVER LABS Europe","start":"Wed, 18 Nov 2020 16:00:00 GMT"}],"vimeo":"https://player.vimeo.com/video/432786265?title=0&byline=0&portrait=0","website":"https://europe.naverlabs.com/emnlp2020","zoom_link":"https://us02web.zoom.us/j/3306875999?pwd=TkhHMGNyVXJSWXN0T1drVU8rajNzUT09","zoom_times":{"Wednesday, Nov 18":[["Wednesday, Nov 18 (09:00-09:45 GMT)","Machine Translation (Papago), Document Information Extraction and Conversational AI at NAVER"],["Wednesday, Nov 18 (16:00-16:30 GMT)","NLP research at NAVER LABS Europe"]]}},{"UID":"salesforce","contacts":[{"email":"audrey.cook@salesforce.com","name":"Audrey Cook"},{"email":"cmccauley@salesforce.com","name":"Caitlin McCauley"}],"description":"Salesforce Research advances AI techniques that pave the path for new AI research directions, innovative products and applications with a positive impact on society. Our team of researchers, engineers, product managers, and designers drive AI innovation across pure research, applied research, and new product incubation- all built on our powerful AI platform. We bring companies and customers together using AI that is explainable, transparent, and accountable.\nAs part of our team you\u2019ll learn unique skills, work with talented people, influence the industry standard for fair and ethical use of artificial intelligence and help us to shape the future of AI.\n","downloads":[{"label":"About Salesforce Research","website":"Salesforce_Research.pdf"},{"label":"Accepted Papers at EMNLP","website":"Salesforce_EMNLP.pdf"},{"label":"Join our AI Research Team","website":"Salesforce_Recruiting.pdf"}],"gather_schedule":[{"duration":2,"label":"Meet Salesforce at Gather.Town","start":"Mon, 16 Nov 2020 20:00:00 GMT"},{"duration":2,"label":"Meet Salesforce at Gather.Town","start":"Tue, 17 Nov 2020 16:00:00 GMT"},{"duration":2,"label":"Meet Salesforce at Gather.Town","start":"Thu, 19 Nov 2020 01:00:00 GMT"},{"duration":2,"label":"Meet Salesforce at Gather.Town","start":"Thu, 19 Nov 2020 20:00:00 GMT"}],"gather_times":{"Monday, Nov 16":[["Monday, Nov 16 (20:00-22:00 GMT)","Meet Salesforce at Gather.Town"]],"Thursday, Nov 19":[["Thursday, Nov 19 (01:00-03:00 GMT)","Meet Salesforce at Gather.Town"],["Thursday, Nov 19 (20:00-22:00 GMT)","Meet Salesforce at Gather.Town"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (16:00-18:00 GMT)","Meet Salesforce at Gather.Town"]]},"grouped_publications":{"Findings":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.438.png","content":{"abstract":"We present BRIDGE, a powerful sequential architecture for modeling dependencies between natural language questions and relational databases in cross-DB semantic parsing. BRIDGE represents the question and DB schema in a tagged sequence where a subset of the fields are augmented with cell values mentioned in the question. The hybrid sequence is encoded by BERT with minimal subsequent layers and the text-DB contextualization is realized via the fine-tuned deep attention in BERT. Combined with a pointer-generator decoder with schema-consistency driven search space pruning, BRIDGE attained state-of-the-art performance on the well-studied Spider benchmark (65.5% dev, 59.2% test), despite being much simpler than most recently proposed models for this task. Our analysis shows that BRIDGE effectively captures the desired cross-modal dependencies and has the potential to generalize to more text-DB related tasks. Our model implementation is available at https://github.com/ salesforce/TabularSemanticParsing.","authors":["Xi Victoria Lin","Richard Socher","Caiming Xiong"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.438","program":"findings","sessions":[],"similar_paper_uids":["findings.438"],"title":"Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing","tldr":"We present BRIDGE, a powerful sequential architecture for modeling dependencies between natural language questions and relational databases in cross-DB semantic parsing. BRIDGE represents the question and DB schema in a tagged sequence where a subset...","track":"Findings of EMNLP"},"forum":"findings.438","id":"findings.438","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.400.png","content":{"abstract":"Existing dialogue state tracking (DST) models require plenty of labeled data. However, collecting high-quality labels is costly, especially when the number of domains increases. In this paper, we address a practical DST problem that is rarely discussed, i.e., learning efficiently with limited labeled data. We present and investigate two self-supervised objectives: preserving latent consistency and modeling conversational behavior. We encourage a DST model to have consistent latent distributions given a perturbed input, making it more robust to an unseen scenario. We also add an auxiliary utterance generation task, modeling a potential correlation between conversational behavior and dialogue states. The experimental results show that our proposed self-supervised signals can improve joint goal accuracy by 8.95% when only 1% labeled data is used on the MultiWOZ dataset. We can achieve an additional 1.76% improvement if some unlabeled data is jointly trained as semi-supervised learning. We analyze and visualize how our proposed self-supervised signals help the DST task and hope to stimulate future data-efficient DST research.","authors":["Chien-Sheng Wu","Steven C.H. Hoi","Caiming Xiong"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.400","program":"findings","sessions":[],"similar_paper_uids":["findings.400"],"title":"Improving Limited Labeled Dialogue State Tracking with Self-Supervision","tldr":"Existing dialogue state tracking (DST) models require plenty of labeled data. However, collecting high-quality labels is costly, especially when the number of domains increases. In this paper, we address a practical DST problem that is rarely discuss...","track":"Findings of EMNLP"},"forum":"findings.400","id":"findings.400","presentation_id":null},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//findings.303.png","content":{"abstract":"In this paper, we focus on generating training examples for few-shot intents in the realistic imbalanced scenario. To build connections between existing many-shot intents and few-shot intents, we consider an intent as a combination of a domain and an action, and propose a composed variational natural language generator (CLANG), a transformer-based conditional variational autoencoder. CLANG utilizes two latent variables to represent the utterances corresponding to two different independent parts (domain and action) in the intent, and the latent variables are composed together to generate natural examples. Additionally, to improve the generator learning, we adopt the contrastive regularization loss that contrasts the in-class with the out-of-class utterance generation given the intent. To evaluate the quality of the generated utterances, experiments are conducted on the generalized few-shot intent detection task. Empirical results show that our proposed model achieves state-of-the-art performances on two real-world intent detection datasets.","authors":["Congying Xia","Caiming Xiong","Philip Yu","Richard Socher"],"demo_url":"","keywords":[""],"material":null,"paper_type":"Findings","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.303","program":"findings","sessions":[],"similar_paper_uids":["findings.303"],"title":"Composed Variational Natural Language Generation for Few-shot Intents","tldr":"In this paper, we focus on generating training examples for few-shot intents in the realistic imbalanced scenario. To build connections between existing many-shot intents and few-shot intents, we consider an intent as a combination of a domain and an...","track":"Findings of EMNLP"},"forum":"findings.303","id":"findings.303","presentation_id":null}],"Long":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.2342.png","content":{"abstract":"A standard way to address different NLP problems is by first constructing a problem-specific dataset, then building a model to fit this dataset. To build the ultimate artificial intelligence, we desire a single machine that can handle diverse new problems, for which task-specific annotations are limited. We bring up textual entailment as a unified solver for such NLP problems. However, current research of textual entailment has not spilled much ink on the following questions: (i) How well does a pretrained textual entailment system generalize across domains with only a handful of domain-specific examples? and  (ii) When is it worth transforming an NLP task into textual entailment? We argue that the transforming is unnecessary if we can obtain rich annotations for this task. Textual entailment really matters particularly when the target NLP task has insufficient annotations.  Universal NLP can be probably achieved through different routines. In this work, we introduce  Universal Few-shot textual Entailment (UFO-Entail). We demonstrate that this framework enables a pretrained entailment model to work well on  new entailment domains in a few-shot setting, and show its effectiveness  as a unified solver for several downstream NLP tasks such as question answering and  coreference resolution  when the end-task annotations are limited.","authors":["Wenpeng Yin","Nazneen Fatema Rajani","Dragomir Radev","Richard Socher","Caiming Xiong"],"demo_url":"","keywords":["nlp problems","textual entailment","nlp task","downstream tasks"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.660","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g5B","start_time":"Wed, 18 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.3470","demo.54","main.3010","main.1923","demo.48"],"title":"Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start","tldr":"A standard way to address different NLP problems is by first constructing a problem-specific dataset, then building a model to fit this dataset. To build the ultimate artificial intelligence, we desire a single machine that can handle diverse new pro...","track":"Semantics: Sentence-level Semantics, Textual Inference and Other areas"},"forum":"main.2342","id":"main.2342","presentation_id":""},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1201.png","content":{"abstract":"The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for language modeling. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream task-oriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.","authors":["Chien-Sheng Wu","Steven C.H. Hoi","Richard Socher","Caiming Xiong"],"demo_url":"","keywords":["language modeling","pre-training","response task","task-oriented applications"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.66","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 02:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z4D","start_time":"Tue, 17 Nov 2020 01:00:00 GMT"}],"similar_paper_uids":["main.1654","main.215","main.1846","main.128","main.3393"],"title":"TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue","tldr":"The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue dataset...","track":"Dialog and Interactive Systems"},"forum":"main.1201","id":"main.1201","presentation_id":"38938861"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.2506.png","content":{"abstract":"The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries.  Training data is generated by applying a series of rule-based transformations to the sentences of source documents.The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.","authors":["Wojciech Kryscinski","Bryan McCann","Caiming Xiong","Richard Socher"],"demo_url":"","keywords":["assessing algorithms","natural inference","fact checking","auxiliary tasks"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.750","program":"main","sessions":[{"end_time":"Thu, 19 Nov 2020 01:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z16C","start_time":"Thu, 19 Nov 2020 00:00:00 GMT"}],"similar_paper_uids":["main.2125","main.1835","main.1023","main.2437","main.2470"],"title":"Evaluating the Factual Consistency of Abstractive Text Summarization","tldr":"The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying...","track":"Summarization"},"forum":"main.2506","id":"main.2506","presentation_id":"38939131"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1654.png","content":{"abstract":"This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks. We approach the problem from two aspects: supervised classifier probe and unsupervised mutual information probe. We fine-tune a feed-forward layer as the classifier probe on top of a fixed pre-trained language model with annotated labels in a supervised way. Meanwhile, we propose an unsupervised mutual information probe to evaluate the mutual dependence between a real clustering and a representation clustering. The goals of this empirical paper are to 1) investigate probing techniques, especially from the unsupervised mutual information aspect, 2) provide guidelines of pre-trained language model selection for the dialogue research community, 3) find insights of pre-training factors for dialogue application that may be the key to success.","authors":["Chien-Sheng Wu","Caiming Xiong"],"demo_url":"","keywords":["task-oriented tasks","supervised probe","unsupervised probe","unsupervised aspect"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.409","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.1201","main.128","main.215","main.2141","main.1006"],"title":"Probing Task-Oriented Dialogue Representation from Language Models","tldr":"This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks. We approach the problem from two aspects: supervised classifier probe and unsuperv...","track":"Dialog and Interactive Systems"},"forum":"main.1654","id":"main.1654","presentation_id":"38938961"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1320.png","content":{"abstract":"Inflectional variation is a common feature of World Englishes such as Colloquial Singapore English and African American Vernacular English. Although comprehension by human readers is usually unimpaired by non-standard inflections, current NLP systems are not yet robust. We propose Base-Inflection Encoding (BITE), a method to tokenize English text by reducing inflected words to their base forms before reinjecting the grammatical information as special symbols. Fine-tuning pretrained NLP models for downstream tasks using our encoding defends against inflectional adversaries while maintaining performance on clean data. Models using BITE generalize better to dialects with non-standard inflections without explicit training and translation models converge faster when trained with BITE. Finally, we show that our encoding improves the vocabulary efficiency of popular data-driven subword tokenizers. Since there has been no prior work on quantitatively evaluating vocabulary efficiency, we propose metrics to do so.","authors":["Samson Tan","Shafiq Joty","Lav Varshney","Min-Yen Kan"],"demo_url":"","keywords":["comprehension","fine-tuning models","downstream tasks","nlp systems"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.455","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 02:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z10A","start_time":"Wed, 18 Nov 2020 01:00:00 GMT"}],"similar_paper_uids":["main.3566","main.2847","main.870","main.701","main.2349"],"title":"Mind Your Inflections! Improving NLP for Non-Standard Englishes with Base-Inflection Encoding","tldr":"Inflectional variation is a common feature of World Englishes such as Colloquial Singapore English and African American Vernacular English. Although comprehension by human readers is usually unimpaired by non-standard inflections, current NLP systems...","track":"Phonology, Morphology and Word Segmentation"},"forum":"main.1320","id":"main.1320","presentation_id":"38938886"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.2050.png","content":{"abstract":"While participants in a multi-party multi-turn conversation simultaneously engage in multiple conversation topics, existing response selection methods are developed mainly focusing on a two-party single-conversation scenario. Hence, the prolongation and transition of conversation topics are ignored by current methods. In this work, we frame response selection as a dynamic topic tracking task to match the topic between the response and relevant conversation context. With this new formulation, we propose a novel multi-task learning framework that supports efficient encoding through large pretrained models with only two utterances at once to perform dynamic topic disentanglement and response selection. We also propose Topic-BERT an essential pretraining step to embed topic information into BERT with self-supervised learning. Experimental results on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response selection and topic disentanglement tasks outperforming existing methods by a good margin.","authors":["Weishi Wang","Steven C.H. Hoi","Shafiq Joty"],"demo_url":"","keywords":["response selection","dynamic task","encoding","dynamic disentanglement"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.533","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g4D","start_time":"Wed, 18 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1863","main.645","main.215","main.1201","main.916"],"title":"Response Selection for Multi-Party Conversations with Dynamic Topic Tracking","tldr":"While participants in a multi-party multi-turn conversation simultaneously engage in multiple conversation topics, existing response selection methods are developed mainly focusing on a two-party single-conversation scenario. Hence, the prolongation ...","track":"Dialog and Interactive Systems"},"forum":"main.2050","id":"main.2050","presentation_id":"38939032"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.355.png","content":{"abstract":"Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such intricate interactions. By contrast, in this work, we propose VD-BERT, a simple yet effective framework of unified vision-dialog Transformer that leverages the pretrained BERT language models for Visual Dialog tasks. The model is unified in that (1) it captures all the interactions between the image and the multi-turn dialog using a single-stream Transformer encoder, and (2) it supports both answer ranking and answer generation seamlessly through the same architecture. More crucially, we adapt  BERT for the effective fusion of vision and dialog contents via visually grounded training. Without the need of pretraining on external vision-language data, our model yields new state of the art, achieving the top position in both single-model and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog leaderboard. Our code and pretrained models are released at https://github.com/salesforce/VD-BERT.","authors":["Yue Wang","Shafiq Joty","Michael Lyu","Irwin King","Caiming Xiong","Steven C.H. Hoi"],"demo_url":"","keywords":["visual dialog","vision-language task","visual tasks","answer ranking"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.269","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 12:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g2G","start_time":"Tue, 17 Nov 2020 10:00:00 GMT"}],"similar_paper_uids":["main.2070","main.1113","main.647","main.2853","TACL.2041"],"title":"VD-BERT: A Unified Vision and Dialog Transformer with BERT","tldr":"Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such int...","track":"Language Grounding to Vision, Robotics and Beyond"},"forum":"main.355","id":"main.355","presentation_id":"38938690"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1622.png","content":{"abstract":"Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose \"Discern\", a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding of both document and dialog. Specifically, we split the document into clause-like elementary discourse units (EDU) using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision \"yes/no/irrelevant\" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark (blind, held-out test set) show that Discern achieves state-of-the-art results of 78.3% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at https://github.com/Yifan-Gao/Discern.","authors":["Yifan Gao","Chien-Sheng Wu","Jingjing Li","Shafiq Joty","Steven C.H. Hoi","Caiming Xiong","Irwin King","Michael Lyu"],"demo_url":"","keywords":["document interpretation","dialog understanding","conversational reading","discern"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.191","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 10:00:00 GMT","hosts":null,"link":"https://zoom.us","session_name":"z6C","start_time":"Tue, 17 Nov 2020 09:00:00 GMT"}],"similar_paper_uids":["main.485","main.2444","main.41","main.527","main.3010"],"title":"Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading","tldr":"Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose \"Discern\", a discourse-aware entailment reasoning network to strengthen the connection and enhance the understa...","track":"Question Answering"},"forum":"main.1622","id":"main.1622","presentation_id":"38938953"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1009.png","content":{"abstract":"Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we proposed Bi-directional Spatio-Temporal Learning (BiST), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved visual cues are used as contextual information to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that BiST achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.","authors":["Hung Le","Doyen Sahoo","Nancy Chen","Steven C.H. Hoi"],"demo_url":"","keywords":["video-grounded dialogues","high-resolution queries","video setting","bi-directional learning"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.145","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1E","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.2839","main.2927","main.1113","main.355","main.1085"],"title":"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues","tldr":"Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over mu...","track":"Dialog and Interactive Systems"},"forum":"main.1009","id":"main.1009","presentation_id":"38938824"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.1012.png","content":{"abstract":"Building an end-to-end conversational agent for multi-domain task-oriented dialogues has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states from all relevant domains, some of which might have shared slots among domains as well as unique slots specifically for one domain only. Second, the dialogue agent must also process various types of information across domains, including dialogue context, dialogue states, and database, to generate natural responses to users. Unlike the existing approaches that are often designed to train each module separately, we propose \"UniConv\" - a novel unified neural architecture for end-to-end conversational systems in multi-domain task-oriented dialogues, which is designed to jointly train (i) a Bi-level State Tracker which tracks dialogue states by learning signals at both slot and domain level independently, and (ii) a Joint Dialogue Act and Response Generator which incorporates information from various input components and models dialogue acts and target responses simultaneously. We conduct comprehensive experiments in dialogue state tracking, context-to-text, and end-to-end settings on the MultiWOZ2.1 benchmark, achieving superior performance over competitive baselines.","authors":["Hung Le","Doyen Sahoo","Chenghao Liu","Nancy Chen","Steven C.H. Hoi"],"demo_url":"","keywords":["multi-domain dialogues","tracking states","end-to-end systems","dialogue tracking"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.146","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g1E","start_time":"Tue, 17 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.1702","main.1201","main.1846","TACL.2143","main.2209"],"title":"UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues","tldr":"Building an end-to-end conversational agent for multi-domain task-oriented dialogues has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states...","track":"Dialog and Interactive Systems"},"forum":"main.1012","id":"main.1012","presentation_id":"38938827"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3217.png","content":{"abstract":"Intent detection is one of the core components of goal-oriented dialog systems, and detecting out-of-scope (OOS) intents is also a practically important skill. Few-shot learning is attracting much attention to mitigate data scarcity, but OOS detection becomes even more challenging. In this paper, we present a simple yet effective approach, discriminative nearest neighbor classification with deep self-attention. Unlike softmax classifiers, we leverage BERT-style pairwise encoding to train a binary classifier that estimates the best matched training example for a user input. We propose to boost the discriminative ability by transferring a natural language inference (NLI) model. Our extensive experiments on a large-scale multi-domain intent detection task show that our method achieves more stable and accurate in-domain and OOS detection accuracy than RoBERTa-based classifiers and embedding-based nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot model to perform competitively with 50-shot or even full-shot classifiers, while we can keep the inference time constant by leveraging a faster embedding retrieval model.","authors":["Jianguo Zhang","Kazuma Hashimoto","Wenhao Liu","Chien-Sheng Wu","Yao Wan","Philip Yu","Richard Socher","Caiming Xiong"],"demo_url":"","keywords":["intent detection","detecting intents","oos detection","large-scale task"],"material":null,"paper_type":"Long","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.411","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.2799","main.148","main.1834","main.2793","main.1032"],"title":"Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference","tldr":"Intent detection is one of the core components of goal-oriented dialog systems, and detecting out-of-scope (OOS) intents is also a practically important skill. Few-shot learning is attracting much attention to mitigate data scarcity, but OOS detectio...","track":"Dialog and Interactive Systems"},"forum":"main.3217","id":"main.3217","presentation_id":"38939288"}],"Short":[{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.517.png","content":{"abstract":"Pre-training in natural language processing makes it easier for an adversary with only query access to a victim model to reconstruct a local copy of the victim by training with gibberish input data paired with the victim's labels for that data. We discover that this extraction process extends to local copies initialized from a pre-trained, multilingual model while the victim remains monolingual. The extracted model learns the task from the monolingual victim, but it generalizes far better than the victim to several other languages. This is done without ever showing the multilingual, extracted model a well-formed input in any of the languages for the target task. We also demonstrate that a few real examples can greatly improve performance, and we analyze how these results shed light on how such extraction methods succeed.","authors":["Nitish Shirish Keskar","Bryan McCann","Caiming Xiong","Richard Socher"],"demo_url":"","keywords":["pre-training","natural processing","victim model","extraction process"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.501","program":"main","sessions":[{"end_time":"Wed, 18 Nov 2020 04:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g4B","start_time":"Wed, 18 Nov 2020 02:00:00 GMT"}],"similar_paper_uids":["main.3116","main.143","main.1997","main.2076","main.2630"],"title":"The Thieves on Sesame Street are Polyglots - Extracting Multilingual Models from Monolingual APIs","tldr":"Pre-training in natural language processing makes it easier for an adversary with only query access to a victim model to reconstruct a local copy of the victim by training with gibberish input data paired with the victim's labels for that data. We di...","track":"Machine Learning for NLP"},"forum":"main.517","id":"main.517","presentation_id":"38938724"},{"card_image_path":"https://raw.githubusercontent.com/acl-org/emnlp-2020-virtual-conference-images/master/paper_images//main.3393.png","content":{"abstract":"The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains - the act of ``request\" carries the same speaker intention whether it is for restaurant reservation or flight booking. However, DA taggers trained on one domain do not generalize well to other domains, which leaves us with the expensive need for a large amount of annotated data in the target domain. In this work, we investigate how to better adapt DA taggers to desired target domains with only unlabeled data. We propose MaskAugment, a controllable mechanism that augments text input by leveraging the pre-trained Mask token from BERT model. Inspired by consistency regularization, we use MaskAugment to introduce an unsupervised teacher-student learning scheme to examine the domain adaptation of DA taggers. Our extensive experiments on the Simulated Dialogue (GSim) and Schema-Guided Dialogue (SGD) datasets show that MaskAugment is useful in improving the cross-domain generalization for DA tagging.","authors":["Semih Yavuz","Kazuma Hashimoto","Wenhao Liu","Nitish Shirish Keskar","Richard Socher","Caiming Xiong"],"demo_url":"","keywords":["da tagging","da","da taggers","maskaugment"],"material":null,"paper_type":"Short","pdf_url":"https://www.aclweb.org/anthology/2020.emnlp-main.412","program":"main","sessions":[{"end_time":"Tue, 17 Nov 2020 20:00:00 GMT","hosts":null,"link":"https://www.virtualchair.net/events/emnlp2020","session_name":"g3F","start_time":"Tue, 17 Nov 2020 18:00:00 GMT"}],"similar_paper_uids":["main.1201","main.478","main.128","main.1846","main.1702"],"title":"Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging","tldr":"The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains - the act of ``request\" carries the same speaker intention whether it is for restaurant reservation or flight booking. However, DA taggers trained on one do...","track":"Dialog and Interactive Systems"},"forum":"main.3393","id":"main.3393","presentation_id":"38939326"}]},"level":"Silver","logo":"salesforce.png","logoontop":true,"name":"Salesforce","publications":["main.2342","main.1201","main.2506","main.1654","main.1320","main.2050","main.355","main.1622","main.1009","main.1012","main.3217","main.517","main.3393","findings.438","findings.400","findings.303"],"resources":[{"label":"IntEx-SemPar: 1st Workshop on Interactive and Executable Semantic Parsing","website":"https://virtual.2020.emnlp.org/workshop_WS-6.html"}],"rocketchat_channel":"sponsor-salesforce","schedule":[{"duration":0.833,"label":"[Spotlight on Salesforce @ EMNLP](https://lnkd.in/gXs_-k5)","start":"Tue, 17 Nov 2020 22:00:00 GMT"},{"duration":0.833,"label":"[Salesforce Research Interns @ EMNLP Panel](https://lnkd.in/gAneh35)","start":"Thu, 19 Nov 2020 00:00:00 GMT"}],"website":"https://einstein.ai/","youtube":"https://www.youtube.com/embed/WeFQAFgYUC0","zoom_link":"https://us02web.zoom.us/j/2733496946?pwd=SmZOL0hNczBTR3k4Y2RCVDNMcGZ1Zz09","zoom_times":{"Thursday, Nov 19":[["Thursday, Nov 19 (00:00-00:49 GMT)","[Salesforce Research Interns @ EMNLP Panel](https://lnkd.in/gAneh35)"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (22:00-22:49 GMT)","[Spotlight on Salesforce @ EMNLP](https://lnkd.in/gXs_-k5)"]]}},{"UID":"zeta_alpha","contacts":[{"email":"zavrel@zeta-alpha.com","name":"Jakub Zavrel"},{"email":"castella@zeta-alpha.com","name":"Sergi Castella Sap\u00e9"},{"email":"zuanazzi@zeta-alpha.com","name":"Victor Zuanazzi"}],"description":"Zeta Alpha is building the next generation Enterprise Search and Insights platform, 100% focused on AI teams.\n\nDo you work in AI, NLP, ML or Data Science and are you finding it increasingly difficult to see the forest for the trees? With hundreds of new publications, technology announcements, and blog postings per day, who can keep up?\n\nOur AI Research Navigator is a powerful state of the art search engine 100% focused on AI content and knowledge. AI Research Navigator combines the latest neural natural language understanding and search technologies, and a user-friendly project workflow to help you locate, discover and organize the AI and Data Science knowledge relevant for your projects. Once you start using it, it will proactively keep you up-to-date on the topics you are interested in. Join us for one of our talks or ask for a demo.\n","downloads":[{"label":"A New Neural Search and Insights Platform for Navigating and Organizing AI Research","website":"zeta_alpha_EMNLP_2020_ack_link.pdf"}],"gather_schedule":[{"end":"Tue, 17 Nov 2020 15:00:00 GMT","label":"Meet Zeta Alpha at Gather.Town","start":"Tue, 17 Nov 2020 09:00:00 GMT"},{"end":"Wed, 18 Nov 2020 15:00:00 GMT","label":"Meet Zeta Alpha at Gather.Town","start":"Wed, 18 Nov 2020 09:00:00 GMT"}],"gather_times":{"Tuesday, Nov 17":[["Tuesday, Nov 17 (09:00-15:00 GMT)","Meet Zeta Alpha at Gather.Town"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (09:00-15:00 GMT)","Meet Zeta Alpha at Gather.Town"]]},"level":"Gold","logo":"zeta-alpha.png","logoontop":true,"name":"Zeta Alpha","nameontop":true,"rocketchat_channel":"sponsor-zeta-alpha","schedule":[{"end":"Mon, 16 Nov 2020 14:30:00 GMT","label":"Meet Zeta Alpha @ EMNLP","start":"Mon, 16 Nov 2020 14:00:00 GMT"},{"end":"Tue, 17 Nov 2020 13:00:00 GMT","label":"Introduction to Zeta Alpha - How to keep up with AI and NLP research?","start":"Tue, 17 Nov 2020 12:30:00 GMT"},{"end":"Tue, 17 Nov 2020 14:30:00 GMT","label":"Demo AI Research Navigator - Exploring trends in NLP","start":"Tue, 17 Nov 2020 14:00:00 GMT"},{"end":"Wed, 18 Nov 2020 10:30:00 GMT","label":"Introduction to Zeta Alpha - How to keep up with AI and NLP research?","start":"Wed, 18 Nov 2020 10:00:00 GMT"},{"end":"Wed, 18 Nov 2020 13:00:00 GMT","label":"Demo AI Research Navigator - Exploring trends in NLP","start":"Wed, 18 Nov 2020 12:30:00 GMT"},{"end":"Wed, 18 Nov 2020 21:30:00 GMT","label":"Zeta Alpha - EMNLP Tropical Party - Drinks on the Beach","start":"Wed, 18 Nov 2020 20:00:00 GMT"}],"website":"https://www.zeta-alpha.com/","youtube":"https://www.youtube.com/embed/vaugp421awo","zoom_link":"https://us02web.zoom.us/j/7768908976?pwd=WDlXOGh6anc2N3RSTHNkbmg4WjFsZz09","zoom_times":{"Monday, Nov 16":[["Monday, Nov 16 (14:00-14:30 GMT)","Meet Zeta Alpha @ EMNLP"]],"Tuesday, Nov 17":[["Tuesday, Nov 17 (12:30-13:00 GMT)","Introduction to Zeta Alpha - How to keep up with AI and NLP research?"],["Tuesday, Nov 17 (14:00-14:30 GMT)","Demo AI Research Navigator - Exploring trends in NLP"]],"Wednesday, Nov 18":[["Wednesday, Nov 18 (10:00-10:30 GMT)","Introduction to Zeta Alpha - How to keep up with AI and NLP research?"],["Wednesday, Nov 18 (12:30-13:00 GMT)","Demo AI Research Navigator - Exploring trends in NLP"],["Wednesday, Nov 18 (20:00-21:30 GMT)","Zeta Alpha - EMNLP Tropical Party - Drinks on the Beach"]]}}]
