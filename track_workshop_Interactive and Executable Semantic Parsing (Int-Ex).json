[{"content":{"abstract":"The current state-of-the-art task-oriented semantic parsing models use BERT or RoBERTa as pretrained encoders; these models have huge memory footprints. This poses a challenge to their deployment for voice assistants such as Amazon Alexa and Google Assistant on edge devices with limited memory budgets. We propose to learn compositional code embeddings to greatly reduce the sizes of BERT-base and RoBERTa-base. We also apply the technique to DistilBERT, ALBERT-base, and ALBERT-large, three already compressed BERT variants which attain similar state-of-the-art performances on semantic parsing with much smaller model sizes. We observe 95.15% 98.46% embedding compression rates and 20.47% 34.22% encoder compression rates, while preserving >97.5% semantic parsing performances. We provide the recipe for training and analyze the trade-off between code embedding sizes and downstream performances.","authors":["Prafull Prakash","Saurabh Kumar Shashidhar","Wenlong Zhao","Subendhu Rongali","Haidar Khan","Michael Kayser"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.423","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Compressing Transformer-Based Semantic Parsing Models using Compositional Code Embeddings","tldr":"The current state-of-the-art task-oriented semantic parsing models use BERT or RoBERTa as pretrained encoders; these models have huge memory footprints. This poses a challenge to their deployment for voice assistants such as Amazon Alexa and Google A...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.3476","presentation_id":"38940116","rocketchat_channel":"paper-intex-sempar2020-3476","speakers":"Prafull Prakash|Saurabh Kumar Shashidhar|Wenlong Zhao|Subendhu Rongali|Haidar Khan|Michael Kayser","title":"Compressing Transformer-Based Semantic Parsing Models using Compositional Code Embeddings"},{"content":{"abstract":"Our goal is to create an interactive natural language interface that efficiently and reliably learns from users to complete tasks in simulated robotics settings. We introduce a neural semantic parsing system that learns new high-level abstractions through decomposition: users interactively teach the system by breaking down high-level utterances describing novel behavior into low-level steps that it can understand. Unfortunately, existing methods either rely on grammars which parse sentences with limited flexibility, or neural sequence-to-sequence models that do not learn efficiently or reliably from individual examples. Our approach bridges this gap, demonstrating the flexibility of modern neural systems, as well as the one-shot reliable generalization of grammar-based methods. Our crowdsourced interactive experiments suggest that over time, users complete complex tasks more efficiently while using our system by leveraging what they just taught. At the same time, getting users to trust the system enough to be incentivized to teach high-level utterances is still an ongoing challenge. We end with a discussion of some of the obstacles we need to overcome to fully realize the potential of the interactive paradigm.","authors":["Siddharth Karamcheti","Dorsa Sadigh","Percy Liang"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.4","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Learning Adaptive Language Interfaces through Decomposition","tldr":"Our goal is to create an interactive natural language interface that efficiently and reliably learns from users to complete tasks in simulated robotics settings. We introduce a neural semantic parsing system that learns new high-level abstractions th...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.10","presentation_id":"38939456","rocketchat_channel":"paper-intex-sempar2020-10","speakers":"Siddharth Karamcheti|Dorsa Sadigh|Percy Liang","title":"Learning Adaptive Language Interfaces through Decomposition"},{"content":{"abstract":"Translating natural language utterances to executable queries is a helpful technique in making the vast amount of data stored in relational databases accessible to a wider range of non-tech-savvy end users. Prior work in this area has largely focused on textual input that is linguistically correct and semantically unambiguous. However, real-world user queries are often succinct, colloquial, and noisy, resembling the input of a search engine. In this work, we introduce data augmentation techniques and a sampling-based content-aware BERT model (ColloQL) to achieve robust text-to-SQL modeling over natural language search (NLS) questions. Due to the lack of evaluation data, we curate a new dataset of NLS questions and demonstrate the efficacy of our approach. ColloQL\u2019s superior performance extends to well-formed text, achieving an 84.9% (logical) and 90.7% (execution) accuracy on the WikiSQL dataset, making it, to the best of our knowledge, the highest performing model that does not use execution guided decoding.","authors":["Karthik Radhakrishnan","Arvind Srikantan","Xi Victoria Lin"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.5","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"ColloQL: Robust Text-to-SQL Over Search Queries","tldr":"Translating natural language utterances to executable queries is a helpful technique in making the vast amount of data stored in relational databases accessible to a wider range of non-tech-savvy end users. Prior work in this area has largely focused...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.11","presentation_id":"38939457","rocketchat_channel":"paper-intex-sempar2020-11","speakers":"Karthik Radhakrishnan|Arvind Srikantan|Xi Victoria Lin","title":"ColloQL: Robust Text-to-SQL Over Search Queries"},{"content":{"abstract":"Generation of natural language responses to the queries of structured language like SQL is very challenging as it requires generalization to new domains and the ability to answer ambiguous queries among other issues. We have participated in the CoSQL shared task organized in the IntEx-SemPar workshop at EMNLP 2020. We have trained a number of Neural Machine Translation (NMT) models to efficiently generate the natural language responses from SQL. Our shuffled back-translation model has led to a BLEU score of 7.47 on the unknown test dataset. In this paper, we will discuss our methodologies to approach the problem and future directions to improve the quality of the generated natural language responses.","authors":["Saptarashmi Bandyopadhyay","Tianyang Zhao"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.6","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Natural Language Response Generation from SQL with Generalization and Back-translation","tldr":"Generation of natural language responses to the queries of structured language like SQL is very challenging as it requires generalization to new domains and the ability to answer ambiguous queries among other issues. We have participated in the CoSQL...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.12","presentation_id":"38939458","rocketchat_channel":"paper-intex-sempar2020-12","speakers":"Saptarashmi Bandyopadhyay|Tianyang Zhao","title":"Natural Language Response Generation from SQL with Generalization and Back-translation"},{"content":{"abstract":"","authors":["Tao Yu","Chien-Sheng Wu","Xi Victoria Lin","Bailin Wang","Yi Chern Tan","Xinyi Yang","Dragomir Radev","Richard Socher","Caiming Xiong"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"GRAPPA: Grammar-Augmented Pre-Training for Table Semantic Parsing","tldr":null,"track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.13","presentation_id":"38939459","rocketchat_channel":"paper-intex-sempar2020-13","speakers":"Tao Yu|Chien-Sheng Wu|Xi Victoria Lin|Bailin Wang|Yi Chern Tan|Xinyi Yang|Dragomir Radev|Richard Socher|Caiming Xiong","title":"GRAPPA: Grammar-Augmented Pre-Training for Table Semantic Parsing"},{"content":{"abstract":"","authors":["Yu Gu","Sue Kase","Michelle Vanni","Brian Sadler","Percy Liang","Xifeng Yan","Yu Su"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Re-thinking Open-domain Semantic Parsing","tldr":null,"track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.14","presentation_id":"38939460","rocketchat_channel":"paper-intex-sempar2020-14","speakers":"Yu Gu|Sue Kase|Michelle Vanni|Brian Sadler|Percy Liang|Xifeng Yan|Yu Su","title":"Re-thinking Open-domain Semantic Parsing"},{"content":{"abstract":"","authors":["Yusen Zhang","Xiangyu Dong","Shuaichen Chang","Tao Yu","Peng Shi","Rui Zhang"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Did You Ask a Good Question? A Cross-Domain Question Intention Classification Benchmark for Text-to-SQL","tldr":null,"track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.15","presentation_id":"38939461","rocketchat_channel":"paper-intex-sempar2020-15","speakers":"Yusen Zhang|Xiangyu Dong|Shuaichen Chang|Tao Yu|Peng Shi|Rui Zhang","title":"Did You Ask a Good Question? A Cross-Domain Question Intention Classification Benchmark for Text-to-SQL"},{"content":{"abstract":"In the era of Big Knowledge Graphs, Question Answering (QA) systems have reached a milestone in their performance and feasibility. However, their applicability, particularly in specific domains such as the biomedical domain, has not gained wide acceptance due to their \u201cblack box\u201d nature, which hinders transparency, fairness, and accountability of QA systems. Therefore, users are unable to understand how and why particular questions have been answered, whereas some others fail. To address this challenge, in this paper, we develop an automatic approach for generating explanations during various stages of a pipeline-based QA system. Our approach is a supervised and automatic approach which considers three classes (i.e., success, no answer, and wrong answer) for annotating the output of involved QA components. Upon our prediction, a template explanation is chosen and integrated into the output of the corresponding component. To measure the effectiveness of the approach, we conducted a user survey as to how non-expert users perceive our generated explanations. The results of our study show a significant increase in the four dimensions of the human factor from the Human-computer interaction community.","authors":["Saeedeh Shekarpour","Abhishek Nadgeri","Kuldeep Singh"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.1","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"QA2Explanation: Generating and Evaluating Explanations for Question Answering Systems over Knowledge Graph","tldr":"In the era of Big Knowledge Graphs, Question Answering (QA) systems have reached a milestone in their performance and feasibility. However, their applicability, particularly in specific domains such as the biomedical domain, has not gained wide accep...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.7","presentation_id":"38939453","rocketchat_channel":"paper-intex-sempar2020-7","speakers":"Saeedeh Shekarpour|Abhishek Nadgeri|Kuldeep Singh","title":"QA2Explanation: Generating and Evaluating Explanations for Question Answering Systems over Knowledge Graph"},{"content":{"abstract":"Collecting training data for semantic parsing is a time-consuming and expensive task. As a result, there is growing interest in industry to reduce the number of annotations required to train a semantic parser, both to cut down on costs and to limit customer data handled by annotators. In this paper, we propose uncertainty and traffic-aware active learning, a novel active learning method that uses model confidence and utterance frequencies from customer traffic to select utterances for annotation. We show that our method significantly outperforms baselines on an internal customer dataset and the Facebook Task Oriented Parsing (TOP) dataset. On our internal dataset, our method achieves the same accuracy as random sampling with 2,000 fewer annotations.","authors":["Priyanka Sen","Emine Yilmaz"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.2","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Uncertainty and Traffic-Aware Active Learning for Semantic Parsing","tldr":"Collecting training data for semantic parsing is a time-consuming and expensive task. As a result, there is growing interest in industry to reduce the number of annotations required to train a semantic parser, both to cut down on costs and to limit c...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.8","presentation_id":"38939454","rocketchat_channel":"paper-intex-sempar2020-8","speakers":"Priyanka Sen|Emine Yilmaz","title":"Uncertainty and Traffic-Aware Active Learning for Semantic Parsing"},{"content":{"abstract":"Task Oriented Parsing (TOP) attempts to map utterances to compositional requests, including multiple intents and their slots. Previous work focus on a tree-based hierarchical meaning representation, and applying constituency parsing techniques to address TOP. In this paper, we propose a new format of meaning representation that is more compact and amenable to sequence-to-sequence (seq-to-seq) models. A simple copy-augmented seq-to-seq parser is built and evaluated over a public TOP dataset, resulting in 3.44% improvement over prior best seq-to-seq parser (exact match accuracy), which is also comparable to constituency parsers\u2019 performance.","authors":["Chaoting Xuan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.intexsempar-1.3","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Improving Sequence-to-Sequence Semantic Parser for Task Oriented Dialog","tldr":"Task Oriented Parsing (TOP) attempts to map utterances to compositional requests, including multiple intents and their slots. Previous work focus on a tree-based hierarchical meaning representation, and applying constituency parsing techniques to add...","track":"Interactive and Executable Semantic Parsing (Int-Ex)"},"id":"WS-6.9","presentation_id":"38939455","rocketchat_channel":"paper-intex-sempar2020-9","speakers":"Chaoting Xuan","title":"Improving Sequence-to-Sequence Semantic Parser for Task Oriented Dialog"}]
