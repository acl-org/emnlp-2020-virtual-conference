[{"content":{"abstract":"Medical code assignment, which predicts medical codes from clinical texts, is a fundamental task of intelligent medical information systems. The emergence of deep models in natural language processing has boosted the development of automatic assignment methods. However, recent advanced neural architectures with flat convolutions or multi-channel feature concatenation ignore the sequential causal constraint within a text sequence and may not learn meaningful clinical text representations, especially for lengthy clinical notes with long-term sequential dependency. This paper proposes a Dilated Convolutional Attention Network (DCAN), integrating dilated convolutions, residual connections, and label attention, for medical code assignment. It adopts dilated convolutions to capture complex medical patterns with a receptive field which increases exponentially with dilation size. Experiments on a real-world clinical dataset empirically show that our model improves the state of the art.","authors":["Shaoxiong Ji","Erik Cambria","Pekka Marttinen"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.8","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Dilated Convolutional Attention Network for Medical Code Assignment from Clinical Text","tldr":"Medical code assignment, which predicts medical codes from clinical texts, is a fundamental task of intelligent medical information systems. The emergence of deep models in natural language processing has boosted the development of automatic assignme...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.1","presentation_id":"38939807","rocketchat_channel":"paper-clinicalnlp-1","speakers":"Shaoxiong Ji|Erik Cambria|Pekka Marttinen","title":"Dilated Convolutional Attention Network for Medical Code Assignment from Clinical Text"},{"content":{"abstract":"Relying on large pretrained language models such as Bidirectional Encoder Representations from Transformers (BERT) for encoding and adding a simple prediction layer has led to impressive performance in many clinical natural language processing (NLP) tasks. In this work, we present a novel extension to the Transformer architecture, by incorporating signature transform with the self-attention model. This architecture is added between embedding and prediction layers. Experiments on a new Swedish prescription data show the proposed architecture to be superior in two of the three information extraction tasks, comparing to baseline models. Finally, we evaluate two different embedding approaches between applying Multilingual BERT and translating the Swedish text to English then encode with a BERT model pretrained on clinical notes.","authors":["John Pougu\u00e9 Biyong","Bo Wang","Terry Lyons","Alejo Nevado-Holgado"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.5","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Information Extraction from Swedish Medical Prescriptions with Sig-Transformer Encoder","tldr":"Relying on large pretrained language models such as Bidirectional Encoder Representations from Transformers (BERT) for encoding and adding a simple prediction layer has led to impressive performance in many clinical natural language processing (NLP) ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.10","presentation_id":"38939813","rocketchat_channel":"paper-clinicalnlp-10","speakers":"John Pougu\u00e9 Biyong|Bo Wang|Terry Lyons|Alejo Nevado-Holgado","title":"Information Extraction from Swedish Medical Prescriptions with Sig-Transformer Encoder"},{"content":{"abstract":"Automated radiology report generation has the potential to reduce the time clinicians spend manually reviewing radiographs and streamline clinical care. However, past work has shown that typical abstractive methods tend to produce fluent, but clinically incorrect radiology reports. In this work, we develop a radiology report generation model utilizing the transformer architecture that produces superior reports as measured by both standard language generation and clinical coherence metrics compared to competitive baselines. We then develop a method to differentiably extract clinical information from generated reports and utilize this differentiability to fine-tune our model to produce more clinically coherent reports.","authors":["Justin Lovelace","Bobak Mortazavi"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.110","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Learning to Generate Clinically Coherent Chest X-Ray Reports","tldr":"Automated radiology report generation has the potential to reduce the time clinicians spend manually reviewing radiographs and streamline clinical care. However, past work has shown that typical abstractive methods tend to produce fluent, but clinica...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.1041","presentation_id":"38940177","rocketchat_channel":"paper-clinicalnlp-1041","speakers":"Justin Lovelace|Bobak Mortazavi","title":"Learning to Generate Clinically Coherent Chest X-Ray Reports"},{"content":{"abstract":"Reading comprehension style question-answering (QA) based on patient-specific documents represents a growing area in clinical NLP with plentiful applications. Bidirectional Encoder Representations from Transformers (BERT) and its derivatives lead the state-of-the-art accuracy on the task, but most evaluation has treated the data as a pre-mixture without systematically looking into the potential effect of imperfect train/test questions. The current study seeks to address this gap by experimenting with full versus partial train/test data consisting of paraphrastic questions. Our key findings include 1) training with all pooled question variants yielded best accuracy, 2) the accuracy varied widely, from 0.74 to 0.80, when trained with each single question variant, and 3) questions of similar lexical/syntactic structure tended to induce identical answers. The results suggest that how you ask questions matters in BERT-based QA, especially at the training stage.","authors":["Sungrim (Riea) Moon","Jungwei Fan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.13","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"How You Ask Matters: The Effect of Paraphrastic Questions to BERT Performance on a Clinical SQuAD Dataset","tldr":"Reading comprehension style question-answering (QA) based on patient-specific documents represents a growing area in clinical NLP with plentiful applications. Bidirectional Encoder Representations from Transformers (BERT) and its derivatives lead the...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.11","presentation_id":"38939814","rocketchat_channel":"paper-clinicalnlp-11","speakers":"Sungrim (Riea) Moon|Jungwei Fan","title":"How You Ask Matters: The Effect of Paraphrastic Questions to BERT Performance on a Clinical SQuAD Dataset"},{"content":{"abstract":"Multiple Sclerosis (MS) is a chronic, inflammatory and degenerative neurological disease, which is monitored by a specialist using the Expanded Disability Status Scale (EDSS) and recorded in unstructured text in the form of a neurology consult note. An EDSS measurement contains an overall \u2018EDSS\u2019 score and several functional subscores. Typically, expert knowledge is required to interpret consult notes and generate these scores. Previous approaches used limited context length Word2Vec embeddings and keyword searches to predict scores given a consult note, but often failed when scores were not explicitly stated. In this work, we present MS-BERT, the first publicly available transformer model trained on real clinical data other than MIMIC. Next, we present MSBC, a classifier that applies MS-BERT to generate embeddings and predict EDSS and functional subscores. Lastly, we explore combining MSBC with other models through the use of Snorkel to generate scores for unlabelled consult notes. MSBC achieves state-of-the-art performance on all metrics and prediction tasks and outperforms the models generated from the Snorkel ensemble. We improve Macro-F1 by 0.12 (to 0.88) for predicting EDSS and on average by 0.29 (to 0.63) for predicting functional subscores over previous Word2Vec CNN and rule-based approaches.","authors":["Alister D\u2019Costa","Stefan Denkovski","Michal Malyska","Sae Young Moon","Brandon Rufino","Zhen Yang","Taylor Killian","Marzyeh Ghassemi"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.2","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Multiple Sclerosis Severity Classification From Clinical Text","tldr":"Multiple Sclerosis (MS) is a chronic, inflammatory and degenerative neurological disease, which is monitored by a specialist using the Expanded Disability Status Scale (EDSS) and recorded in unstructured text in the form of a neurology consult note. ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.12","presentation_id":"38939815","rocketchat_channel":"paper-clinicalnlp-12","speakers":"Alister D\u2019Costa|Stefan Denkovski|Michal Malyska|Sae Young Moon|Brandon Rufino|Zhen Yang|Taylor Killian|Marzyeh Ghassemi","title":"Multiple Sclerosis Severity Classification From Clinical Text"},{"content":{"abstract":"Automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, specifically for radiology reports, as most healthcare institutes use either no template or department/institute specific templates. Moreover, radiologists\u2019 reporting style varies from one to another as sentences are written in a telegraphic format and do not follow general English grammar rules. In this work, we present an ensemble method that consolidates the predictions of three models, capturing various attributes of textual information for automatic labeling of sentences with section labels. These three models are: 1) Focus Sentence model, capturing context of the target sentence; 2) Surrounding Context model, capturing the neighboring context of the target sentence; and finally, 3) Formatting/Layout model, aimed at learning report formatting cues. We utilize Bi-directional LSTMs, followed by sentence encoders, to acquire the context. Furthermore, we define several features that incorporate the structure of reports. We compare our proposed approach against multiple baselines and state-of-the-art approaches on a proprietary dataset as well as 100 manually annotated radiology notes from the MIMIC-III dataset, which we are making publicly available. Our proposed approach significantly outperforms other approaches by achieving 97.1% accuracy.","authors":["Morteza Pourreza Shahri","Amir Tahmasebi","Bingyang Ye","Henghui Zhu","Javed Aslam","Timothy Ferris"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.28","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"An Ensemble Approach to Automatic Structuring of Radiology Reports","tldr":"Automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, speci...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.13","presentation_id":"38939816","rocketchat_channel":"paper-clinicalnlp-13","speakers":"Morteza Pourreza Shahri|Amir Tahmasebi|Bingyang Ye|Henghui Zhu|Javed Aslam|Timothy Ferris","title":"An Ensemble Approach to Automatic Structuring of Radiology Reports"},{"content":{"abstract":"Stroke is one of the leading causes of death and disability worldwide. Stroke is treatable, but it is prone to disability after treatment and must be prevented. To grasp the degree of disability caused by stroke, we use magnetic resonance imaging text records to predict stroke and measure the performance according to the document-level and sentence-level representation. As a result of the experiment, the document-level representation shows better performance.","authors":["Tak-Sung Heo","Chulho Kim","Jeong-Myeong Choi","Yeong-Seok Jeong","Yu-Seop Kim"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.1","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Various Approaches for Predicting Stroke Prognosis using Magnetic Resonance Imaging Text Records","tldr":"Stroke is one of the leading causes of death and disability worldwide. Stroke is treatable, but it is prone to disability after treatment and must be prevented. To grasp the degree of disability caused by stroke, we use magnetic resonance imaging tex...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.15","presentation_id":"38939817","rocketchat_channel":"paper-clinicalnlp-15","speakers":"Tak-Sung Heo|Chulho Kim|Jeong-Myeong Choi|Yeong-Seok Jeong|Yu-Seop Kim","title":"Various Approaches for Predicting Stroke Prognosis using Magnetic Resonance Imaging Text Records"},{"content":{"abstract":"Extracting and modeling temporal information in clinical text is an important element for developing timelines and disease trajectories. Time information in written text varies in preciseness and explicitness, posing challenges for NLP approaches that aim to accurately anchor temporal information on a timeline. Relative and incomplete time expressions (RI-Timexes) are expressions that require additional information for their temporal anchor to be resolved, but few studies have addressed this challenge specifically. In this study, we aimed to reproduce and verify a classification approach for identifying anchor dates and relations in clinical text, and propose a novel relation classification approach for this task.","authors":["Louise Dupuis","Nicol Bergou","Hegler Tissot","Sumithra Velupillai"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.14","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Relative and Incomplete Time Expression Anchoring for Clinical Text","tldr":"Extracting and modeling temporal information in clinical text is an important element for developing timelines and disease trajectories. Time information in written text varies in preciseness and explicitness, posing challenges for NLP approaches tha...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.16","presentation_id":"38939818","rocketchat_channel":"paper-clinicalnlp-16","speakers":"Louise Dupuis|Nicol Bergou|Hegler Tissot|Sumithra Velupillai","title":"Relative and Incomplete Time Expression Anchoring for Clinical Text"},{"content":{"abstract":"Automatic medical image report generation has drawn growing attention due to its potential to alleviate radiologists\u2019 workload. Existing work on report generation often trains encoder-decoder networks to generate complete reports. However, such models are affected by data bias (e.g. label imbalance) and face common issues inherent in text generation models (e.g. repetition). In this work, we focus on reporting abnormal findings on radiology images; instead of training on complete radiology reports, we propose a method to identify abnormal findings from the reports in addition to grouping them with unsupervised clustering and minimal rules. We formulate the task as cross-modal retrieval and propose Conditional Visual-Semantic Embeddings to align images and fine-grained abnormal findings in a joint embedding space. We demonstrate that our method is able to retrieve abnormal findings and outperforms existing generation models on both clinical correctness and text generation metrics.","authors":["Jianmo Ni","Chun-Nan Hsu","Amilcare Gentili","Julian McAuley"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.176","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on Chest X-rays","tldr":"Automatic medical image report generation has drawn growing attention due to its potential to alleviate radiologists\u2019 workload. Existing work on report generation often trains encoder-decoder networks to generate complete reports. However, such model...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.1640","presentation_id":"38940178","rocketchat_channel":"paper-clinicalnlp-1640","speakers":"Jianmo Ni|Chun-Nan Hsu|Amilcare Gentili|Julian McAuley","title":"Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on Chest X-rays"},{"content":{"abstract":"One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.","authors":["Zhi Wen","Xing Han Lu","Siva Reddy"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.15","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining","tldr":"One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designe...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.17","presentation_id":"38939819","rocketchat_channel":"paper-clinicalnlp-17","speakers":"Zhi Wen|Xing Han Lu|Siva Reddy","title":"MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining"},{"content":{"abstract":"Machine learning models depend on the quality of input data. As electronic health records are widely adopted, the amount of data in health care is growing, along with complaints about the quality of medical notes. We use two prediction tasks, readmission prediction and in-hospital mortality prediction, to characterize the value of information in medical notes. We show that as a whole, medical notes only provide additional predictive power over structured information in readmission prediction. We further propose a probing framework to select parts of notes that enable more accurate predictions than using all notes, despite that the selected information leads to a distribution shift from the training data (\u201call notes\u201d). Finally, we demonstrate that models trained on the selected valuable information achieve even better predictive performance, with only 6.8%of all the tokens for readmission prediction.","authors":["Chao-Chun Hsu","Shantanu Karnwal","Sendhil Mullainathan","Ziad Obermeyer","Chenhao Tan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.187","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Characterizing the Value of Information in Medical Notes","tldr":"Machine learning models depend on the quality of input data. As electronic health records are widely adopted, the amount of data in health care is growing, along with complaints about the quality of medical notes. We use two prediction tasks, readmis...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.1713","presentation_id":"38940179","rocketchat_channel":"paper-clinicalnlp-1713","speakers":"Chao-Chun Hsu|Shantanu Karnwal|Sendhil Mullainathan|Ziad Obermeyer|Chenhao Tan","title":"Characterizing the Value of Information in Medical Notes"},{"content":{"abstract":"We evaluate several biomedical contextual embeddings (based on BERT, ELMo, and Flair) for the detection of medication entities such as Drugs and Adverse Drug Events (ADE) from Electronic Health Records (EHR) using the 2018 ADE and Medication Extraction (Track 2) n2c2 data-set. We identify best practices for transfer learning, such as language-model fine-tuning and scalar mix. Our transfer learning models achieve strong performance in the overall task (F1=92.91%) as well as in ADE identification (F1=53.08%). Flair-based embeddings out-perform in the identification of context-dependent entities such as ADE. BERT-based embeddings out-perform in recognizing clinical terminology such as Drug and Form entities. ELMo-based embeddings deliver competitive performance in all entities. We develop a sentence-augmentation method for enhanced ADE identification benefiting BERT-based and ELMo-based models by up to 3.13% in F1 gains. Finally, we show that a simple ensemble of these models out-paces most current methods in ADE extraction (F1=55.77%).","authors":["Sankaran Narayanan","Kaivalya Mannam","Sreeranga P Rajan","P Venkat Rangan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.6","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Evaluation of Transfer Learning for Adverse Drug Event (ADE) and Medication Entity Extraction","tldr":"We evaluate several biomedical contextual embeddings (based on BERT, ELMo, and Flair) for the detection of medication entities such as Drugs and Adverse Drug Events (ADE) from Electronic Health Records (EHR) using the 2018 ADE and Medication Extracti...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.18","presentation_id":"38939820","rocketchat_channel":"paper-clinicalnlp-18","speakers":"Sankaran Narayanan|Kaivalya Mannam|Sreeranga P Rajan|P Venkat Rangan","title":"Evaluation of Transfer Learning for Adverse Drug Event (ADE) and Medication Entity Extraction"},{"content":{"abstract":"In this work, we propose a novel goal-oriented dialog task, automatic symptom detection. We build a system that can interact with patients through dialog to detect and collect clinical symptoms automatically, which can save a doctor\u2019s time interviewing the patient. Given a set of explicit symptoms provided by the patient to initiate a dialog for diagnosing, the system is trained to collect implicit symptoms by asking questions, in order to collect more information for making an accurate diagnosis. After getting the reply from the patient for each question, the system also decides whether current information is enough for a human doctor to make a diagnosis. To achieve this goal, we propose two neural models and a training pipeline for the multi-step reasoning task. We also build a knowledge graph as additional inputs to further improve model performance. Experiments show that our model significantly outperforms the baseline by 4%, discovering 67% of implicit symptoms on average with a limited number of questions.","authors":["Hongyin Luo","Shang-Wen Li","James Glass"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.16","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Knowledge Grounded Conversational Symptom Detection with Graph Memory Networks","tldr":"In this work, we propose a novel goal-oriented dialog task, automatic symptom detection. We build a system that can interact with patients through dialog to detect and collect clinical symptoms automatically, which can save a doctor\u2019s time interviewi...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.19","presentation_id":"38939821","rocketchat_channel":"paper-clinicalnlp-19","speakers":"Hongyin Luo|Shang-Wen Li|James Glass","title":"Knowledge Grounded Conversational Symptom Detection with Graph Memory Networks"},{"content":{"abstract":"A large array of pretrained models are available to the biomedical NLP (BioNLP) community. Finding the best model for a particular task can be difficult and time-consuming. For many applications in the biomedical and clinical domains, it is crucial that models can be built quickly and are highly accurate. We present a large-scale study across 18 established biomedical and clinical NLP tasks to determine which of several popular open-source biomedical and clinical NLP models work well in different settings. Furthermore, we apply recent advances in pretraining to train new biomedical language models, and carefully investigate the effect of various design choices on downstream performance. Our best models perform well in all of our benchmarks, and set new State-of-the-Art in 9 tasks. We release these models in the hope that they can help the community to speed up and increase the accuracy of BioNLP and text mining applications.","authors":["Patrick Lewis","Myle Ott","Jingfei Du","Veselin Stoyanov"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.17","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art","tldr":"A large array of pretrained models are available to the biomedical NLP (BioNLP) community. Finding the best model for a particular task can be difficult and time-consuming. For many applications in the biomedical and clinical domains, it is crucial t...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.20","presentation_id":"38939822","rocketchat_channel":"paper-clinicalnlp-20","speakers":"Patrick Lewis|Myle Ott|Jingfei Du|Veselin Stoyanov","title":"Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art"},{"content":{"abstract":"Reducing rates of early hospital readmission has been recognized and identified as a key to improve quality of care and reduce costs. There are a number of risk factors that have been hypothesized to be important for understanding re-admission risk, including such factors as problems with substance abuse, ability to maintain work, relations with family. In this work, we develop Roberta-based models to predict the sentiment of sentences describing readmission risk factors in discharge summaries of patients with psychosis. We improve substantially on previous results by a scheme that shares information across risk factors while also allowing the model to learn risk factor-specific information.","authors":["Xiyu Ding","Mei-Hua Hall","Timothy Miller"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.4","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Incorporating Risk Factor Embeddings in Pre-trained Transformers Improves Sentiment Prediction in Psychiatric Discharge Summaries","tldr":"Reducing rates of early hospital readmission has been recognized and identified as a key to improve quality of care and reduce costs. There are a number of risk factors that have been hypothesized to be important for understanding re-admission risk, ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.21","presentation_id":"38939823","rocketchat_channel":"paper-clinicalnlp-21","speakers":"Xiyu Ding|Mei-Hua Hall|Timothy Miller","title":"Incorporating Risk Factor Embeddings in Pre-trained Transformers Improves Sentiment Prediction in Psychiatric Discharge Summaries"},{"content":{"abstract":"The language used by physicians and health professionals in prescription directions includes medical jargon and implicit directives and causes much confusion among patients. Human intervention to simplify the language at the pharmacies may introduce additional errors that can lead to potentially severe health outcomes. We propose a novel machine translation-based approach, PharmMT, to automatically and reliably simplify prescription directions into patient-friendly language, thereby significantly reducing pharmacist workload. We evaluate the proposed approach over a dataset consisting of over 530K prescriptions obtained from a large mail-order pharmacy. The end-to-end system achieves a BLEU score of 60.27 against the reference directions generated by pharmacists, a 39.6% relative improvement over the rule-based normalization. Pharmacists judged 94.3% of the simplified directions as usable as-is or with minimal changes. This work demonstrates the feasibility of a machine translation-based tool for simplifying prescription directions in real-life.","authors":["Jiazhao Li","Corey Lester","Xinyan Zhao","Yuting Ding","Yun Jiang","V.G.Vinod Vydiswaran"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.251","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"PharmMT: A Neural Machine Translation Approach to Simplify Prescription Directions","tldr":"The language used by physicians and health professionals in prescription directions includes medical jargon and implicit directives and causes much confusion among patients. Human intervention to simplify the language at the pharmacies may introduce ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.2127","presentation_id":"38940180","rocketchat_channel":"paper-clinicalnlp-2127","speakers":"Jiazhao Li|Corey Lester|Xinyan Zhao|Yuting Ding|Yun Jiang|V.G.Vinod Vydiswaran","title":"PharmMT: A Neural Machine Translation Approach to Simplify Prescription Directions"},{"content":{"abstract":"Bidirectional Encoder Representations from Transformers (BERT) models achieve state-of-the-art performance on a number of Natural Language Processing tasks. However, their model size on disk often exceeds 1 GB and the process of fine-tuning them and using them to run inference consumes significant hardware resources and runtime. This makes them hard to deploy to production environments. This paper fine-tunes DistilBERT, a lightweight deep learning model, on medical text for the named entity recognition task of Protected Health Information (PHI) and medical concepts. This work provides a full assessment of the performance of DistilBERT in comparison with BERT models that were pre-trained on medical text. For Named Entity Recognition task of PHI, DistilBERT achieved almost the same results as medical versions of BERT in terms of F1 score at almost half the runtime and consuming approximately half the disk space. On the other hand, for the detection of medical concepts, DistilBERT\u2019s F1 score was lower by 4 points on average than medical BERT variants.","authors":["Macarious Abadeer"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.18","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Assessment of DistilBERT performance on Named Entity Recognition task for the detection of Protected Health Information and medical concepts","tldr":"Bidirectional Encoder Representations from Transformers (BERT) models achieve state-of-the-art performance on a number of Natural Language Processing tasks. However, their model size on disk often exceeds 1 GB and the process of fine-tuning them and ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.23","presentation_id":"38939824","rocketchat_channel":"paper-clinicalnlp-23","speakers":"Macarious Abadeer","title":"Assessment of DistilBERT performance on Named Entity Recognition task for the detection of Protected Health Information and medical concepts"},{"content":{"abstract":"","authors":["Zixu Wang","Julia Ive","Sinead Moylett","Christoph Mueller","Rudolf Cardinal","Sumithra Velupillai","John O'Brien","Robert Stewart"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Distinguishing between Dementia with Lewy bodies (DLB) and Alzheimer's Disease (AD) using Mental Health Records: a Classification Approach","tldr":null,"track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.25","presentation_id":"38939825","rocketchat_channel":"paper-clinicalnlp-25","speakers":"Zixu Wang|Julia Ive|Sinead Moylett|Christoph Mueller|Rudolf Cardinal|Sumithra Velupillai|John O'Brien|Robert Stewart","title":"Distinguishing between Dementia with Lewy bodies (DLB) and Alzheimer's Disease (AD) using Mental Health Records: a Classification Approach"},{"content":{"abstract":"An adverse drug event (ADE) is an injury resulting from medical intervention related to a drug. Automatic ADE detection from text is either fine-grained (ADE entity recognition) or coarse-grained (ADE assertive sentence classification), with limited efforts leveraging inter-dependencies among the two granularities. We instead propose a multi-grained joint deep network to concurrently learn the ADE entity recognition and ADE sentence classification tasks. Our joint approach takes advantage of their symbiotic relationship, with a transfer of knowledge between the two levels of granularity. Our dual-attention mechanism constructs multiple distinct representations of a sentence that capture both task-specific and semantic information in the sentence, providing stronger emphasis on the key elements essential for sentence classification. Our model improves state-of- art F1-score for both tasks: (i) entity recognition of ADE words (12.5% increase) and (ii) ADE sentence classification (13.6% increase) on MADE 1.0 benchmark of EHR notes.","authors":["Susmitha Wunnava","Xiao Qin","Tabassum Kakar","Xiangnan Kong","Elke Rundensteiner"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.306","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"A Dual-Attention Network for Joint Named Entity Recognition and Sentence Classification of Adverse Drug Events","tldr":"An adverse drug event (ADE) is an injury resulting from medical intervention related to a drug. Automatic ADE detection from text is either fine-grained (ADE entity recognition) or coarse-grained (ADE assertive sentence classification), with limited ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.2509","presentation_id":"38940181","rocketchat_channel":"paper-clinicalnlp-2509","speakers":"Susmitha Wunnava|Xiao Qin|Tabassum Kakar|Xiangnan Kong|Elke Rundensteiner","title":"A Dual-Attention Network for Joint Named Entity Recognition and Sentence Classification of Adverse Drug Events"},{"content":{"abstract":"Automated Medication Regimen (MR) extraction from medical conversations can not only improve recall and help patients follow through with their care plan, but also reduce the documentation burden for doctors. In this paper, we focus on extracting spans for frequency, route and change, corresponding to medications discussed in the conversation. We first describe a unique dataset of annotated doctor-patient conversations and then present a weakly supervised model architecture that can perform span extraction using noisy classification data. The model utilizes an attention bottleneck inside a classification model to perform the extraction. We experiment with several variants of attention scoring and projection functions and propose a novel transformer-based attention scoring function (TAScore). The proposed combination of TAScore and Fusedmax projection achieves a 10 point increase in Longest Common Substring F1 compared to the baseline of additive scoring plus softmax projection.","authors":["Dhruvesh Patel","Sandeep Konam","Sai Prabhakar"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.20","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Weakly Supervised Medication Regimen Extraction from Medical Conversations","tldr":"Automated Medication Regimen (MR) extraction from medical conversations can not only improve recall and help patients follow through with their care plan, but also reduce the documentation burden for doctors. In this paper, we focus on extracting spa...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.26","presentation_id":"38939826","rocketchat_channel":"paper-clinicalnlp-26","speakers":"Dhruvesh Patel|Sandeep Konam|Sai Prabhakar","title":"Weakly Supervised Medication Regimen Extraction from Medical Conversations"},{"content":{"abstract":"We present work on extraction of radiotherapy treatment information from the clinical narrative in the electronic medical records. Radiotherapy is a central component of the treatment of most solid cancers. Its details are described in non-standardized fashions using jargon not found in other medical specialties, complicating the already difficult task of manual data extraction. We examine the performance of several state-of-the-art neural methods for relation extraction of radiotherapy treatment details, with a goal of automating detailed information extraction. The neural systems perform at 0.82-0.88 macro-average F1, which approximates or in some cases exceeds the inter-annotator agreement. To the best of our knowledge, this is the first effort to develop models for radiotherapy relation extraction and one of the few efforts for relation extraction to describe cancer treatment in general.","authors":["Danielle Bitterman","Timothy Miller","David Harris","Chen Lin","Sean Finan","Jeremy Warner","Raymond Mak","Guergana Savova"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.21","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Extracting Relations between Radiotherapy Treatment Details","tldr":"We present work on extraction of radiotherapy treatment information from the clinical narrative in the electronic medical records. Radiotherapy is a central component of the treatment of most solid cancers. Its details are described in non-standardiz...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.27","presentation_id":"38939827","rocketchat_channel":"paper-clinicalnlp-27","speakers":"Danielle Bitterman|Timothy Miller|David Harris|Chen Lin|Sean Finan|Jeremy Warner|Raymond Mak|Guergana Savova","title":"Extracting Relations between Radiotherapy Treatment Details"},{"content":{"abstract":"Understanding a medical conversation between a patient and a physician poses unique natural language understanding challenge since it combines elements of standard open-ended conversation with very domain-specific elements that require expertise and medical knowledge. Summarization of medical conversations is a particularly important aspect of medical conversation understanding since it addresses a very real need in medical practice: capturing the most important aspects of a medical encounter so that they can be used for medical decision making and subsequent follow ups. In this paper we present a novel approach to medical conversation summarization that leverages the unique and independent local structures created when gathering a patient\u2019s medical history. Our approach is a variation of the pointer generator network where we introduce a penalty on the generator distribution, and we explicitly model negations. The model also captures important properties of medical conversations such as medical knowledge coming from standardized medical ontologies better than when those concepts are introduced explicitly. Through evaluation by doctors, we show that our approach is preferred on twice the number of summaries to the baseline pointer generator model and captures most or all of the information in 80% of the conversations making it a realistic alternative to costly manual summarization by medical experts.","authors":["Anirudh Joshi","Namit Katariya","Xavier Amatriain","Anitha Kannan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.335","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting Local Structures.","tldr":"Understanding a medical conversation between a patient and a physician poses unique natural language understanding challenge since it combines elements of standard open-ended conversation with very domain-specific elements that require expertise and ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.2801","presentation_id":"38940182","rocketchat_channel":"paper-clinicalnlp-2801","speakers":"Anirudh Joshi|Namit Katariya|Xavier Amatriain|Anitha Kannan","title":"Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting Local Structures."},{"content":{"abstract":"One of the fundamental goals of artificial intelligence is to build computer-based expert systems. Inferring clinical diagnoses to generate a clinical assessment during a patient encounter is a crucial step towards building a medical diagnostic system. Previous works were mainly based on either medical domain-specific knowledge, or patients\u2019 prior diagnoses and clinical encounters. In this paper, we propose a novel model for automated clinical assessment generation (MCAG). MCAG is built on an innovative graph neural network, where rich clinical knowledge is incorporated into an end-to-end corpus-learning system. Our evaluation results against physician generated gold standard show that MCAG significantly improves the BLEU and rouge score compared with competitive baseline models. Further, physicians\u2019 evaluation showed that MCAG could generate high-quality assessments.","authors":["Zhichao Yang","Hong Yu"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.findings-emnlp.336","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Generating Accurate Electronic Health Assessment from Medical Graph","tldr":"One of the fundamental goals of artificial intelligence is to build computer-based expert systems. Inferring clinical diagnoses to generate a clinical assessment during a patient encounter is a crucial step towards building a medical diagnostic syste...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.2804","presentation_id":"38940183","rocketchat_channel":"paper-clinicalnlp-2804","speakers":"Zhichao Yang|Hong Yu","title":"Generating Accurate Electronic Health Assessment from Medical Graph"},{"content":{"abstract":"In this work we describe the Waiting List Corpus consisting of de-identified referrals for several specialty consultations from the waiting list in Chilean public hospitals. A subset of 900 referrals was manually annotated with 9,029 entities, 385 attributes, and 284 pairs of relations with clinical relevance. A trained medical doctor annotated these referrals, and then together with other three researchers, consolidated each of the annotations. The annotated corpus has nested entities, with 32.2% of entities embedded in other entities. We use this annotated corpus to obtain preliminary results for Named Entity Recognition (NER). The best results were achieved by using a biLSTM-CRF architecture using word embeddings trained over Spanish Wikipedia together with clinical embeddings computed by the group. NER models applied to this corpus can leverage statistics of diseases and pending procedures within this waiting list. This work constitutes the first annotated corpus using clinical narratives from Chile, and one of the few for the Spanish language. The annotated corpus, the clinical word embeddings, and the annotation guidelines are freely released to the research community.","authors":["Pablo B\u00e1ez","Fabi\u00e1n Villena","Mat\u00edas Rojas","Manuel Dur\u00e1n","Jocelyn Dunstan"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.32","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"The Chilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in Spanish","tldr":"In this work we describe the Waiting List Corpus consisting of de-identified referrals for several specialty consultations from the waiting list in Chilean public hospitals. A subset of 900 referrals was manually annotated with 9,029 entities, 385 at...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.29","presentation_id":"38939828","rocketchat_channel":"paper-clinicalnlp-29","speakers":"Pablo B\u00e1ez|Fabi\u00e1n Villena|Mat\u00edas Rojas|Manuel Dur\u00e1n|Jocelyn Dunstan","title":"The Chilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in Spanish"},{"content":{"abstract":"Loss of consciousness, so-called syncope, is a commonly occurring symptom associated with worse prognosis for a number of heart-related diseases. We present a comparison of methods for a diagnosis classification task in Norwegian clinical notes, targeting syncope, i.e. fainting cases. We find that an often neglected baseline with keyword matching constitutes a rather strong basis, but more advanced methods do offer some improvement in classification performance, especially a convolutional neural network model. The developed pipeline is planned to be used for quantifying unregistered syncope cases in Norway.","authors":["Ildiko Pilan","P\u00e5l H. Brekke","Fredrik A. Dahl","Tore Gundersen","Haldor Husby","\u00d8ystein Nytr\u00f8","Lilja \u00d8vrelid"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.9","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Classification of Syncope Cases in Norwegian Medical Records","tldr":"Loss of consciousness, so-called syncope, is a commonly occurring symptom associated with worse prognosis for a number of heart-related diseases. We present a comparison of methods for a diagnosis classification task in Norwegian clinical notes, targ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.3","presentation_id":"38939808","rocketchat_channel":"paper-clinicalnlp-3","speakers":"Ildiko Pilan|P\u00e5l H. Brekke|Fredrik A. Dahl|Tore Gundersen|Haldor Husby|\u00d8ystein Nytr\u00f8|Lilja \u00d8vrelid","title":"Classification of Syncope Cases in Norwegian Medical Records"},{"content":{"abstract":"With the growing number of electronic health record data, clinical NLP tasks have become increasingly relevant to unlock valuable information from unstructured clinical text. Although the performance of downstream NLP tasks, such as named-entity recognition (NER), in English corpus has recently improved by contextualised language models, less research is available for clinical texts in low resource languages. Our goal is to assess a deep contextual embedding model for Portuguese, so called BioBERTpt, to support clinical and biomedical NER. We transfer learned information encoded in a multilingual-BERT model to a corpora of clinical narratives and biomedical-scientific papers in Brazilian Portuguese. To evaluate the performance of BioBERTpt, we ran NER experiments on two annotated corpora containing clinical narratives and compared the results with existing BERT models. Our in-domain model outperformed the baseline model in F1-score by 2.72%, achieving higher performance in 11 out of 13 assessed entities. We demonstrate that enriching contextual embedding models with domain literature can play an important role in improving performance for specific NLP tasks. The transfer learning process enhanced the Portuguese biomedical NER model by reducing the necessity of labeled data and the demand for retraining a whole new model.","authors":["Elisa Terumi Rubel Schneider","Jo\u00e3o Vitor Andrioli de Souza","Julien Knafou","Lucas Emanuel Silva e Oliveira","Jenny Copara","Yohan Bonescki Gumiel","Lucas Ferro Antunes de Oliveira","Emerson Cabrera Paraiso","Douglas Teodoro","Cl\u00e1udia Maria Cabral Moro Barra"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.7","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"BioBERTpt - A Portuguese Neural Language Model for Clinical Named Entity Recognition","tldr":"With the growing number of electronic health record data, clinical NLP tasks have become increasingly relevant to unlock valuable information from unstructured clinical text. Although the performance of downstream NLP tasks, such as named-entity reco...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.30","presentation_id":"38939829","rocketchat_channel":"paper-clinicalnlp-30","speakers":"Elisa Terumi Rubel Schneider|Jo\u00e3o Vitor Andrioli de Souza|Julien Knafou|Lucas Emanuel Silva e Oliveira|Jenny Copara|Yohan Bonescki Gumiel|Lucas Ferro Antunes de Oliveira|Emerson Cabrera Paraiso|Douglas Teodoro|Cl\u00e1udia Maria Cabral Moro Barra","title":"BioBERTpt - A Portuguese Neural Language Model for Clinical Named Entity Recognition"},{"content":{"abstract":"A cancer registry is a critical and massive database for which various types of domain knowledge are needed and whose maintenance requires labor-intensive data curation. In order to facilitate the curation process for building a high-quality and integrated cancer registry database, we compiled a cross-hospital corpus and applied neural network methods to develop a natural language processing system for extracting cancer registry variables buried in unstructured pathology reports. The performance of the developed networks was compared with various baselines using standard micro-precision, recall and F-measure. Furthermore, we conducted experiments to study the feasibility of applying transfer learning to rapidly develop a well-performing system for processing reports from different sources that might be presented in different writing styles and formats. The results demonstrate that the transfer learning method enables us to develop a satisfactory system for a new hospital with only a few annotations and suggest more opportunities to reduce the burden of cancer registry curation.","authors":["Yan-Jie Lin","Hong-Jie Dai","You-Chen Zhang","Chung-Yang Wu","Yu-Cheng Chang","Pin-Jou Lu","Chih-Jen Huang","Yu-Tsang Wang","Hui-Min Hsieh","Kun-San Chao","Tsang-Wu Liu","I-Shou Chang","Yi-Hsin Connie Yang","Ti-Hao Wang","Ko-Jiunn Liu","Li-Tzong Chen","Sheau-Fang Yang"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.22","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Cancer Registry Information Extraction via Transfer Learning","tldr":"A cancer registry is a critical and massive database for which various types of domain knowledge are needed and whose maintenance requires labor-intensive data curation. In order to facilitate the curation process for building a high-quality and inte...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.31","presentation_id":"38939830","rocketchat_channel":"paper-clinicalnlp-31","speakers":"Yan-Jie Lin|Hong-Jie Dai|You-Chen Zhang|Chung-Yang Wu|Yu-Cheng Chang|Pin-Jou Lu|Chih-Jen Huang|Yu-Tsang Wang|Hui-Min Hsieh|Kun-San Chao|Tsang-Wu Liu|I-Shou Chang|Yi-Hsin Connie Yang|Ti-Hao Wang|Ko-Jiunn Liu|Li-Tzong Chen|Sheau-Fang Yang","title":"Cancer Registry Information Extraction via Transfer Learning"},{"content":{"abstract":"Recent studies have shown that adversarial examples can be generated by applying small perturbations to the inputs such that the well- trained deep learning models will misclassify. With the increasing number of safety and security-sensitive applications of deep learn- ing models, the robustness of deep learning models has become a crucial topic. The robustness of deep learning models for health- care applications is especially critical because the unique characteristics and the high financial interests of the medical domain make it more sensitive to adversarial attacks. Among the modalities of medical data, the clinical summaries have higher risks to be attacked because they are generated by third-party companies. As few works studied adversarial threats on clinical summaries, in this work we first apply adversarial attack to clinical summaries of electronic health records (EHR) to show the text-based deep learning systems are vulnerable to adversarial examples. Secondly, benefiting from the multi-modality of the EHR dataset, we propose a novel defense method, MATCH (Multimodal feATure Consistency cHeck), which leverages the consistency between multiple modalities in the data to defend against adversarial examples on a single modality. Our experiments demonstrate the effectiveness of MATCH on a hospital readmission prediction task comparing with baseline methods.","authors":["Wenjie Wang","Youngja Park","Taesung Lee","Ian Molloy","Pengfei Tang","Li Xiong"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.29","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Utilizing Multimodal Feature Consistency to Detect Adversarial Examples on Clinical Summaries","tldr":"Recent studies have shown that adversarial examples can be generated by applying small perturbations to the inputs such that the well- trained deep learning models will misclassify. With the increasing number of safety and security-sensitive applicat...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.33","presentation_id":"38939831","rocketchat_channel":"paper-clinicalnlp-33","speakers":"Wenjie Wang|Youngja Park|Taesung Lee|Ian Molloy|Pengfei Tang|Li Xiong","title":"Utilizing Multimodal Feature Consistency to Detect Adversarial Examples on Clinical Summaries"},{"content":{"abstract":"De-identification is the task of identifying protected health information (PHI) in the clinical text. Existing neural de-identification models often fail to generalize to a new dataset. We propose a simple yet effective data augmentation method PHICON to alleviate the generalization issue. PHICON consists of PHI augmentation and Context augmentation, which creates augmented training corpora by replacing PHI entities with named-entities sampled from external sources, and by changing background context with synonym replacement or random word insertion, respectively. Experimental results on the i2b2 2006 and 2014 de-identification challenge datasets show that PHICON can help three selected de-identification models boost F1-score (by at most 8.6%) on cross-dataset test setting. We also discuss how much augmentation to use and how each augmentation method influences the performance.","authors":["Xiang Yue","Shuang Zhou"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.23","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"PHICON: Improving Generalization of Clinical Text De-identification Models via Data Augmentation","tldr":"De-identification is the task of identifying protected health information (PHI) in the clinical text. Existing neural de-identification models often fail to generalize to a new dataset. We propose a simple yet effective data augmentation method PHICO...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.37","presentation_id":"38939832","rocketchat_channel":"paper-clinicalnlp-37","speakers":"Xiang Yue|Shuang Zhou","title":"PHICON: Improving Generalization of Clinical Text De-identification Models via Data Augmentation"},{"content":{"abstract":"In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via \u201cexpert-review\u201d, where clinicians can have a dialogue with a domain expert (reviewers) and ask them questions about data entry rules. Automatically identifying \u201creal questions\u201d in these dialogues could uncover ambiguities or common problems in data capturing in a given clinical setting. In this study, we proposed a novel multi-channel deep convolutional neural network architecture, namely Quest-CNN, for the purpose of separating real questions that expect an answer (information or help) about an issue from sentences that are not questions, as well as from questions referring to an issue mentioned in a nearby sentence (e.g., can you clarify this?), which we will refer as \u201cc-questions\u201d. We conducted a comprehensive performance comparison analysis of the proposed multi-channel deep convolutional neural network against other deep neural networks. Furthermore, we evaluated the performance of traditional rule-based and learning-based methods for detecting question sentences. The proposed Quest-CNN achieved the best F1 score both on a dataset of data entry-review dialogue in a dialysis care setting, and on a general domain dataset.","authors":["George Michalopoulos","Helen Chen","Alexander Wong"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.24","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Where\u2019s the Question? A Multi-channel Deep Convolutional Neural Network for Question Identification in Textual Data","tldr":"In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via \u201cexpert-review...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.38","presentation_id":"38939833","rocketchat_channel":"paper-clinicalnlp-38","speakers":"George Michalopoulos|Helen Chen|Alexander Wong","title":"Where\u2019s the Question? A Multi-channel Deep Convolutional Neural Network for Question Identification in Textual Data"},{"content":{"abstract":"We address the problem of model generalization for sequence to sequence (seq2seq) architectures. We propose going beyond data augmentation via paraphrase-optimized multi-task learning and observe that it is useful in correctly handling unseen sentential paraphrases as inputs. Our models greatly outperform SOTA seq2seq models for semantic parsing on diverse domains (Overnight - up to 3.2% and emrQA - 7%) and Nematus, the winning solution for WMT 2017, for Czech to English translation (CzENG 1.6 - 1.5 BLEU).","authors":["So Yeon Min","Preethi Raghavan","Peter Szolovits"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.30","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Advancing Seq2seq with Joint Paraphrase Learning","tldr":"We address the problem of model generalization for sequence to sequence (seq2seq) architectures. We propose going beyond data augmentation via paraphrase-optimized multi-task learning and observe that it is useful in correctly handling unseen sentent...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.39","presentation_id":"38939834","rocketchat_channel":"paper-clinicalnlp-39","speakers":"So Yeon Min|Preethi Raghavan|Peter Szolovits","title":"Advancing Seq2seq with Joint Paraphrase Learning"},{"content":{"abstract":"In this paper, we evaluate several machine learning methods for multi-label classification of text questions. Every nursing student in the United States must pass the National Council Licensure Examination (NCLEX) to begin professional practice. NCLEX defines a number of competencies on which students are evaluated. By labeling test questions with NCLEX competencies, we can score students according to their performance in each competency. This information helps instructors measure how prepared students are for the NCLEX, as well as which competencies they may need help with. A key challenge is that questions may be related to more than one competency. Labeling questions with NCLEX competencies, therefore, equates to a multi-label, text classification problem where each competency is a label. Here we present an evaluation of several methods to support this use case along with a proposed approach. While our work is grounded in the nursing education domain, the methods described here can be used for any multi-label, text classification use case.","authors":["John Langton","Krishna Srihasam","Junlin Jiang"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.10","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Comparison of Machine Learning Methods for Multi-label Classification of Nursing Education and Licensure Exam Questions","tldr":"In this paper, we evaluate several machine learning methods for multi-label classification of text questions. Every nursing student in the United States must pass the National Council Licensure Examination (NCLEX) to begin professional practice. NCLE...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.4","presentation_id":"38939809","rocketchat_channel":"paper-clinicalnlp-4","speakers":"John Langton|Krishna Srihasam|Junlin Jiang","title":"Comparison of Machine Learning Methods for Multi-label Classification of Nursing Education and Licensure Exam Questions"},{"content":{"abstract":"Domain pretraining followed by task fine-tuning has become the standard paradigm for NLP tasks, but requires in-domain labelled data for task fine-tuning. To overcome this, we propose to utilise domain unlabelled data by assigning pseudo labels from a general model. We evaluate the approach on two clinical STS datasets, and achieve r= 0.80 on N2C2-STS. Further investigation reveals that if the data distribution of unlabelled sentence pairs is closer to the test data, we can obtain better performance. By leveraging a large general-purpose STS dataset and small-scale in-domain training data, we obtain further improvements to r= 0.90, a new SOTA.","authors":["Yuxia Wang","Karin Verspoor","Timothy Baldwin"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.25","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Learning from Unlabelled Data for Clinical Semantic Textual Similarity","tldr":"Domain pretraining followed by task fine-tuning has become the standard paradigm for NLP tasks, but requires in-domain labelled data for task fine-tuning. To overcome this, we propose to utilise domain unlabelled data by assigning pseudo labels from ...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.40","presentation_id":"38939835","rocketchat_channel":"paper-clinicalnlp-40","speakers":"Yuxia Wang|Karin Verspoor|Timothy Baldwin","title":"Learning from Unlabelled Data for Clinical Semantic Textual Similarity"},{"content":{"abstract":"ICD coding is the task of classifying and cod-ing all diagnoses, symptoms and proceduresassociated with a patient\u2019s visit. The process isoften manual, extremely time-consuming andexpensive for hospitals as clinical interactionsare usually recorded in free text medical notes.In this paper, we propose a machine learningmodel, BERT-XML, for large scale automatedICD coding of EHR notes, utilizing recentlydeveloped unsupervised pretraining that haveachieved state of the art performance on a va-riety of NLP tasks. We train a BERT modelfrom scratch on EHR notes, learning with vo-cabulary better suited for EHR tasks and thusoutperform off-the-shelf models. We furtheradapt the BERT architecture for ICD codingwith multi-label attention. We demonstratethe effectiveness of BERT-based models on thelarge scale ICD code classification task usingmillions of EHR notes to predict thousands ofunique codes.","authors":["Zachariah Zhang","Jingshu Liu","Narges Razavian"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.3","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining","tldr":"ICD coding is the task of classifying and cod-ing all diagnoses, symptoms and proceduresassociated with a patient\u2019s visit. The process isoften manual, extremely time-consuming andexpensive for hospitals as clinical interactionsare usually recorded in...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.43","presentation_id":"38939836","rocketchat_channel":"paper-clinicalnlp-43","speakers":"Zachariah Zhang|Jingshu Liu|Narges Razavian","title":"BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining"},{"content":{"abstract":"In drug development, protocols define how clinical trials are conducted, and are therefore of paramount importance. They contain key patient-, investigator-, medication-, and study-related information, often elaborated in different sections in the protocol texts. Granular-level parsing on large quantity of existing protocols can accelerate clinical trial design and provide actionable insights into trial optimization. Here, we report our progresses in using deep learning NLP algorithms to enable automated protocol analytics. In particular, we combined a pre-trained BERT transformer model with joint-learning strategies to simultaneously identify clinically relevant entities (i.e. Named Entity Recognition) and extract the syntactic relations between these entities (i.e. Relation Extraction) from the eligibility criteria section in protocol texts. When comparing to standalone NER and RE models, our joint-learning strategy can effectively improve the performance of RE task while retaining similarly high NER performance, likely due to the synergy of optimizing toward both tasks\u2019 objectives via shared parameters. The derived NLP model provides an end-to-end solution to convert unstructured protocol texts into structured data source, which will be embedded into a comprehensive clinical analytics workflow for downstream trial design missions such like patient population extraction, patient enrollment rate estimation, and protocol amendment prediction.","authors":["Miao Chen","Ganhui Lan","Fang Du","Victor Lobanov"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.26","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Joint Learning with Pre-trained Transformer on Named Entity Recognition and Relation Extraction Tasks for Clinical Analytics","tldr":"In drug development, protocols define how clinical trials are conducted, and are therefore of paramount importance. They contain key patient-, investigator-, medication-, and study-related information, often elaborated in different sections in the pr...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.44","presentation_id":"38939837","rocketchat_channel":"paper-clinicalnlp-44","speakers":"Miao Chen|Ganhui Lan|Fang Du|Victor Lobanov","title":"Joint Learning with Pre-trained Transformer on Named Entity Recognition and Relation Extraction Tasks for Clinical Analytics"},{"content":{"abstract":"Clinical machine learning is increasingly multimodal, collected in both structured tabular formats and unstructured forms such as free text. We propose a novel task of exploring fairness on a multimodal clinical dataset, adopting equalized odds for the downstream medical prediction tasks. To this end, we investigate a modality-agnostic fairness algorithm - equalized odds post processing - and compare it to a text-specific fairness algorithm: debiased clinical word embeddings. Despite the fact that debiased word embeddings do not explicitly address equalized odds of protected groups, we show that a text-specific approach to fairness may simultaneously achieve a good balance of performance classical notions of fairness. Our work opens the door for future work at the critical intersection of clinical NLP and fairness.","authors":["John Chen","Ian Berlot-Attwell","Xindi Wang","Safwan Hossain","Frank Rudzicz"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.33","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Analyzing Text Specific vs Blackbox Fairness Algorithms in Multimodal Clinical NLP","tldr":"Clinical machine learning is increasingly multimodal, collected in both structured tabular formats and unstructured forms such as free text. We propose a novel task of exploring fairness on a multimodal clinical dataset, adopting equalized odds for t...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.48","presentation_id":"38939838","rocketchat_channel":"paper-clinicalnlp-48","speakers":"John Chen|Ian Berlot-Attwell|Xindi Wang|Safwan Hossain|Frank Rudzicz","title":"Analyzing Text Specific vs Blackbox Fairness Algorithms in Multimodal Clinical NLP"},{"content":{"abstract":"Eligibility criteria in the clinical trials specify the characteristics that a patient must or must not possess in order to be treated according to a standard clinical care guideline. As the process of manual eligibility determination is time-consuming, automatic structuring of the eligibility criteria into various semantic categories or aspects is the need of the hour. Existing methods use hand-crafted rules and feature-based statistical machine learning methods to dynamically induce semantic aspects. However, in order to deal with paucity of aspect-annotated clinical trials data, we propose a novel weakly-supervised co-training based method which can exploit a large pool of unlabeled criteria sentences to augment the limited supervised training data, and consequently enhance the performance. Experiments with 0.2M criteria sentences show that the proposed approach outperforms the competitive supervised baselines by 12% in terms of micro-averaged F1 score for all the aspects. Probing deeper into analysis, we observe domain-specific information boosts up the performance by a significant margin.","authors":["Tirthankar Dasgupta","Ishani Mondal","Abir Naskar","Lipika Dey"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.27","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Extracting Semantic Aspects for Structured Representation of Clinical Trial Eligibility Criteria","tldr":"Eligibility criteria in the clinical trials specify the characteristics that a patient must or must not possess in order to be treated according to a standard clinical care guideline. As the process of manual eligibility determination is time-consumi...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.49","presentation_id":"38939839","rocketchat_channel":"paper-clinicalnlp-49","speakers":"Tirthankar Dasgupta|Ishani Mondal|Abir Naskar|Lipika Dey","title":"Extracting Semantic Aspects for Structured Representation of Clinical Trial Eligibility Criteria"},{"content":{"abstract":"Clinical notes contain rich information, which is relatively unexploited in predictive modeling compared to structured data. In this work, we developed a new clinical text representation Clinical XLNet that leverages the temporal information of the sequence of the notes. We evaluated our models on prolonged mechanical ventilation prediction problem and our experiments demonstrated that Clinical XLNet outperforms the best baselines consistently. The models and scripts are made publicly available.","authors":["Kexin Huang","Abhishek Singh","Sitong Chen","Edward Moseley","Chih-Ying Deng","Naomi George","Charolotta Lindvall"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.11","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Clinical XLNet: Modeling Sequential Clinical Notes and Predicting Prolonged Mechanical Ventilation","tldr":"Clinical notes contain rich information, which is relatively unexploited in predictive modeling compared to structured data. In this work, we developed a new clinical text representation Clinical XLNet that leverages the temporal information of the s...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.6","presentation_id":"38939810","rocketchat_channel":"paper-clinicalnlp-6","speakers":"Kexin Huang|Abhishek Singh|Sitong Chen|Edward Moseley|Chih-Ying Deng|Naomi George|Charolotta Lindvall","title":"Clinical XLNet: Modeling Sequential Clinical Notes and Predicting Prolonged Mechanical Ventilation"},{"content":{"abstract":"Lymph node status plays a pivotal role in the treatment of cancer. The extraction of lymph nodes from radiology text reports enables large-scale training of lymph node detection on MRI. In this work, we first propose an ontology of 41 types of abdominal lymph nodes with a hierarchical relationship. We then introduce an end-to-end approach based on the combination of rules and transformer-based methods to detect these abdominal lymph node mentions and classify their types from the MRI radiology reports. We demonstrate the superior performance of a model fine-tuned on MRI reports using BlueBERT, called MriBERT. We find that MriBERT outperforms the rule-based labeler (0.957 vs 0.644 in micro weighted F1-score) as well as other BERT-based variations (0.913 - 0.928). We make the code and MriBERT publicly available at https://github.com/ncbi-nlp/bluebert, with the hope that this method can facilitate the development of medical report annotators to produce labels from scratch at scale.","authors":["Yifan Peng","Sungwon Lee","Daniel C. Elton","Thomas Shen","Yu-xing Tang","Qingyu Chen","Shuai Wang","Yingying Zhu","Ronald Summers","Zhiyong Lu"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.12","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Automatic recognition of abdominal lymph nodes from clinical text","tldr":"Lymph node status plays a pivotal role in the treatment of cancer. The extraction of lymph nodes from radiology text reports enables large-scale training of lymph node detection on MRI. In this work, we first propose an ontology of 41 types of abdomi...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.7","presentation_id":"38939811","rocketchat_channel":"paper-clinicalnlp-7","speakers":"Yifan Peng|Sungwon Lee|Daniel C. Elton|Thomas Shen|Yu-xing Tang|Qingyu Chen|Shuai Wang|Yingying Zhu|Ronald Summers|Zhiyong Lu","title":"Automatic recognition of abdominal lymph nodes from clinical text"},{"content":{"abstract":"Ample evidence suggests that better machine learning models may be steadily obtained by training on increasingly larger datasets on natural language processing (NLP) problems from non-medical domains. Whether the same holds true for medical NLP has by far not been thoroughly investigated. This work shows that this is indeed not always the case. We reveal the somehow counter-intuitive observation that performant medical NLP models may be obtained with small amount of labeled data, quite the opposite to the common belief, most likely due to the domain specificity of the problem. We show quantitatively the effect of training data size on a fixed test set composed of two of the largest public chest x-ray radiology report datasets on the task of abnormality classification. The trained models not only make use of the training data efficiently, but also outperform the current state-of-the-art rule-based systems by a significant margin.","authors":["Jean-Baptiste Lamare","Oloruntobiloba Olatunji","Li Yao"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.31","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"On the diminishing return of labeling clinical reports","tldr":"Ample evidence suggests that better machine learning models may be steadily obtained by training on increasingly larger datasets on natural language processing (NLP) problems from non-medical domains. Whether the same holds true for medical NLP has b...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.8","presentation_id":"38939812","rocketchat_channel":"paper-clinicalnlp-8","speakers":"Jean-Baptiste Lamare|Oloruntobiloba Olatunji|Li Yao","title":"On the diminishing return of labeling clinical reports"},{"content":{"abstract":"While Dementia with Lewy Bodies (DLB) is the second most common type of neurodegenerative dementia following Alzheimer\u2019s Disease (AD), it is difficult to distinguish from AD. We propose a method for DLB detection by using mental health record (MHR) documents from a (3-month) period before a patient has been diagnosed with DLB or AD. Our objective is to develop a model that could be clinically useful to differentiate between DLB and AD across datasets from different healthcare institutions. We cast this as a classification task using Convolutional Neural Network (CNN), an efficient neural model for text classification. We experiment with different representation models, and explore the features that contribute to model performances. In addition, we apply temperature scaling, a simple but efficient model calibration method, to produce more reliable predictions. We believe the proposed method has important potential for clinical applications using routine healthcare records, and for generalising to other relevant clinical record datasets. To the best of our knowledge, this is the first attempt to distinguish DLB from AD using mental health records, and to improve the reliability of DLB predictions.","authors":["Zixu Wang","Julia Ive","Sinead Moylett","Christoph Mueller","Rudolf Cardinal","Sumithra Velupillai","John O\u2019Brien","Robert Stewart"],"demo_url":null,"keywords":[],"material":null,"paper_type":"Workshop","pdf_url":"https://www.aclweb.org/anthology/2020.clinicalnlp-1.19","program":"workshop","sessions":[],"similar_paper_uids":[],"title":"Distinguishing between Dementia with Lewy bodies (DLB) and Alzheimer\u2019s Disease (AD) using Mental Health Records: a Classification Approach","tldr":"While Dementia with Lewy Bodies (DLB) is the second most common type of neurodegenerative dementia following Alzheimer\u2019s Disease (AD), it is difficult to distinguish from AD. We propose a method for DLB detection by using mental health record (MHR) d...","track":"3rd Clinical Natural Language Processing Workshop (Clinical NLP 2020)"},"id":"WS-12.2020.clinicalnlp-1.19","presentation_id":"","rocketchat_channel":"paper-clinicalnlp-19","speakers":"Zixu Wang|Julia Ive|Sinead Moylett|Christoph Mueller|Rudolf Cardinal|Sumithra Velupillai|John O\u2019Brien|Robert Stewart","title":"Distinguishing between Dementia with Lewy bodies (DLB) and Alzheimer\u2019s Disease (AD) using Mental Health Records: a Classification Approach"}]
